{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(file):\n",
    "    data = pd.read_csv(file)\n",
    "    print('Raw shape: ',data.shape)\n",
    "    data['Date'] = pd.to_datetime(data.Date)\n",
    "    print('Days: ',len(set(data.Date)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(df,zones):\n",
    "    df = df.loc[df['PULocationID'].isin(zones)]\n",
    "    table = pd.pivot_table(df, values='vehicle_count', index=['Date','Hour'],\n",
    "                    columns=['PULocationID'], aggfunc=np.sum, fill_value=0)\n",
    "#     table.columns = [i[1] for i in table.columns]\n",
    "    missing_columns = [i for i in zones if i not in table.columns]\n",
    "    for col in missing_columns:\n",
    "        table[col] = 0\n",
    "    table = table[sorted(table.columns)]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscoreNormalizeSpatial(matrix):\n",
    "    m = matrix.copy()\n",
    "    for i in range(m.shape[0]):\n",
    "        m[i, :] = (m[i, :] - m[i, :].mean()) / (m[i, :].std()+1e-10)\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(matrix):\n",
    "    m = matrix.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(m)\n",
    "    t = scaler.transform(m)\n",
    "    return scaler, t\n",
    "def inverse_standardize(matrix, scaler):\n",
    "    t = matrix.copy()\n",
    "    return scaler.inverse_transform(t)\n",
    "def getPCAFeatures(matrix, n=10):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(matrix)\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "    reducedMatrixPCA.shape\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return pca,reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_standardize(matrix, scaler):\n",
    "    t = matrix.copy()\n",
    "    return scaler.inverse_transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPCAFeatures(matrix, n=10):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(matrix)\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "    reducedMatrixPCA.shape\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return pca,reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_pca(matrix,pca):\n",
    "    m = matrix.copy()\n",
    "    return pca.inverse_transform(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLag(dataset, maxlag, lagColumns):\n",
    "    dataset_list = [dataset]\n",
    "\n",
    "    for l in range(1, maxlag+1):\n",
    "        df = dataset.shift(l)\n",
    "        df = df[lagColumns]\n",
    "        df.columns = [c+'_lag_'+str(l) for c in df.columns]\n",
    "        dataset_list.append(df)\n",
    "\n",
    "    dataset = pd.concat(dataset_list, axis=1).dropna()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train PCA from 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = gpd.read_file('../../Data/NYC Taxi Zones.geojson')\n",
    "zones = zone['location_id'].unique()\n",
    "zones = [int(i) for i in zones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = 'PENN'\n",
    "pca_comps = 6\n",
    "dataDir = '/home/mingyi/Dropbox/UrbanTemporalNetworks/processedData/'\n",
    "file = dataDir + hub + 'VehicleByHour2018toHub.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape:  (2251320, 4)\n",
      "Days:  365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-01-01</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "PULocationID     1    2    3    4    5    6    7    8    9    10   ...  254  \\\n",
       "Date       Hour                                                    ...        \n",
       "2018-01-01 0       0    0    0    3    0    0    2    0    0    0  ...    0   \n",
       "           1       0    0    0    4    0    0    0    0    0    0  ...    0   \n",
       "           2       0    0    0    4    0    0    1    0    0    0  ...    0   \n",
       "           3       0    0    0    1    0    0    0    0    0    0  ...    0   \n",
       "           4       0    0    0    2    0    0    1    0    0    0  ...    0   \n",
       "\n",
       "PULocationID     255  256  257  258  259  260  261  262  263  \n",
       "Date       Hour                                               \n",
       "2018-01-01 0       2    0    0    0    0    0    2    2    4  \n",
       "           1       5    2    0    0    0    0    3    2    5  \n",
       "           2       5    3    1    0    0    0    2    2    4  \n",
       "           3       6    1    0    0    0    0    1    3    1  \n",
       "           4       4    1    0    0    0    2    1    0    3  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2018 = loadData(file)\n",
    "data2018 = getTimeSeries(data2018,zones)\n",
    "data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2018 = data2018.values.astype(np.float64)\n",
    "scaler, s_matrix2018 = standardize(matrix2018)\n",
    "pca,pca_data2018 = getPCAFeatures(s_matrix2018,n=pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19663817456851498"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(s_matrix2018,pca.inverse_transform(pca_data2018))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = dataDir + hub + 'VehicleByHour2019toHub.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape:  (2295120, 4)\n",
      "Days:  365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8760, 260)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadData(file)\n",
    "data = getTimeSeries(data,zones)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = data.values.astype(np.float64)\n",
    "scaler, s_matrix = standardize(matrix)\n",
    "pcaData = pd.DataFrame(pca.transform(s_matrix),columns=[str(i) for i in range(1,pca_comps+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20128970485444733"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(s_matrix,pca.inverse_transform(pcaData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaData.index = data.index\n",
    "pcaData = pcaData.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "externalDataDir = \"/home/mingyi/Dropbox/UrbanTemporalNetworks/HongData/\"+hub+'2019/'\n",
    "extFile = externalDataDir+\"external.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>arrival</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>DOW</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thur</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  arrival  PRCP  SNOW  SNWD  TMAX  DOW  Tue  Wed  Thur  \\\n",
       "0  2019-01-01     0      0.0  0.06   0.0   0.0  58.0    1    1    0     0   \n",
       "1  2019-01-01     1      1.0  0.06   0.0   0.0  58.0    1    1    0     0   \n",
       "\n",
       "   Fri  Sat  Sun  \n",
       "0    0    0    0  \n",
       "1    0    0    0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf = pd.read_csv(extFile)\n",
    "print(extDf.shape)\n",
    "extDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Hour', 'arrival', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'DOW', 'Tue',\n",
       "       'Wed', 'Thur', 'Fri', 'Sat', 'Sun'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Date', 'Hour', 'arrival', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'DOW', 'Tue',\n",
    "       'Wed', 'Thur', 'Fri', 'Sat', 'Sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extDf = extDf[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.030547</td>\n",
       "      <td>-1.001798</td>\n",
       "      <td>3.496616</td>\n",
       "      <td>-0.987254</td>\n",
       "      <td>0.728032</td>\n",
       "      <td>0.644526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.432136</td>\n",
       "      <td>0.270773</td>\n",
       "      <td>5.300683</td>\n",
       "      <td>-0.272211</td>\n",
       "      <td>2.444349</td>\n",
       "      <td>2.660221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.845671</td>\n",
       "      <td>1.224228</td>\n",
       "      <td>6.868527</td>\n",
       "      <td>-0.824515</td>\n",
       "      <td>2.617295</td>\n",
       "      <td>2.201111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.280333</td>\n",
       "      <td>-1.467905</td>\n",
       "      <td>4.316622</td>\n",
       "      <td>-0.290135</td>\n",
       "      <td>1.283292</td>\n",
       "      <td>1.412003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.942900</td>\n",
       "      <td>1.871800</td>\n",
       "      <td>2.422403</td>\n",
       "      <td>1.601848</td>\n",
       "      <td>-0.396678</td>\n",
       "      <td>-0.012601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>7.088500</td>\n",
       "      <td>1.310887</td>\n",
       "      <td>3.454726</td>\n",
       "      <td>-0.735921</td>\n",
       "      <td>5.619978</td>\n",
       "      <td>2.980029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>-0.957523</td>\n",
       "      <td>1.156819</td>\n",
       "      <td>1.014788</td>\n",
       "      <td>0.203702</td>\n",
       "      <td>0.941755</td>\n",
       "      <td>1.302584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>-1.170588</td>\n",
       "      <td>0.764983</td>\n",
       "      <td>0.619514</td>\n",
       "      <td>0.044183</td>\n",
       "      <td>2.146228</td>\n",
       "      <td>1.404606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>-1.914261</td>\n",
       "      <td>2.534923</td>\n",
       "      <td>1.170349</td>\n",
       "      <td>0.304297</td>\n",
       "      <td>-0.595720</td>\n",
       "      <td>1.565992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>-4.293097</td>\n",
       "      <td>0.576788</td>\n",
       "      <td>1.686053</td>\n",
       "      <td>1.847415</td>\n",
       "      <td>0.244004</td>\n",
       "      <td>-0.028819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4         5         6\n",
       "0    -0.030547 -1.001798  3.496616 -0.987254  0.728032  0.644526\n",
       "1     2.432136  0.270773  5.300683 -0.272211  2.444349  2.660221\n",
       "2     2.845671  1.224228  6.868527 -0.824515  2.617295  2.201111\n",
       "3    -1.280333 -1.467905  4.316622 -0.290135  1.283292  1.412003\n",
       "4    -3.942900  1.871800  2.422403  1.601848 -0.396678 -0.012601\n",
       "...        ...       ...       ...       ...       ...       ...\n",
       "8755  7.088500  1.310887  3.454726 -0.735921  5.619978  2.980029\n",
       "8756 -0.957523  1.156819  1.014788  0.203702  0.941755  1.302584\n",
       "8757 -1.170588  0.764983  0.619514  0.044183  2.146228  1.404606\n",
       "8758 -1.914261  2.534923  1.170349  0.304297 -0.595720  1.565992\n",
       "8759 -4.293097  0.576788  1.686053  1.847415  0.244004 -0.028819\n",
       "\n",
       "[8760 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_data2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 8)\n",
      "(8760, 14)\n"
     ]
    }
   ],
   "source": [
    "print(pcaData.shape)\n",
    "print(extDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaData['Date'] = pd.to_datetime(pcaData['Date'])\n",
    "extDf['Date'] = pd.to_datetime(extDf['Date'])\n",
    "pcaData['Hour'] = pcaData['Hour'].astype(int)\n",
    "extDf['Hour'] = extDf['Hour'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 20)\n"
     ]
    }
   ],
   "source": [
    "pcaData = pd.merge(pcaData,extDf, on=['Date', 'Hour'], how='left')\n",
    "print(pcaData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Hour', '1', '2', '3', '4', '5', '6', 'arrival', 'PRCP', 'SNOW',\n",
       "       'SNWD', 'TMAX', 'DOW', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat', 'Sun'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagColumns = ['arrival'] + [str(i) for i in range(1,1+pca_comps)]\n",
    "\n",
    "DateColumns = ['Date']\n",
    "\n",
    "targetColumns = [str(i) for i in range(1,1+pca_comps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8748, 104)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlag = 12\n",
    "\n",
    "pcaData_lag = addLag(pcaData, maxlag, lagColumns)\n",
    "\n",
    "pcaData_lag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2018 data with externality\n",
    "pca_data2018.index = data2018.index\n",
    "pca_data2018 = pca_data2018.reset_index()\n",
    "externalDataDir = \"/home/mingyi/Dropbox/UrbanTemporalNetworks/HongData/\"+hub+'2018/'\n",
    "extFile = externalDataDir+\"external.csv\"\n",
    "extDf = pd.read_csv(extFile)\n",
    "extDf = extDf[selected_columns]\n",
    "\n",
    "pca_data2018['Date'] = pd.to_datetime(pca_data2018['Date'])\n",
    "extDf['Date'] = pd.to_datetime(extDf['Date'])\n",
    "pca_data2018['Hour'] = pca_data2018['Hour'].astype(int)\n",
    "extDf['Hour'] = extDf['Hour'].astype(int)\n",
    "\n",
    "pca_data2018 = pd.merge(pca_data2018,extDf, on=['Date', 'Hour'], how='left')\n",
    "\n",
    "pca_data2018_lag = addLag(pca_data2018, maxlag, lagColumns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_real_value = data[12:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month:  1\n",
      "Train Size:  (1760, 104)\n",
      "Test Size:  (732, 104)\n"
     ]
    }
   ],
   "source": [
    "CommR2List = []\n",
    "EdgeR2List = []\n",
    "residualDf_list = []\n",
    "rawList = []\n",
    "networkPrediction = pd.DataFrame()\n",
    "\n",
    "for m in range(1,13):\n",
    "\n",
    "    print(\"month: \",m)\n",
    "\n",
    "    dataset_train = pd.concat([pca_data2018_lag.loc[pca_data2018_lag.Date.dt.month>=m],\n",
    "                               pcaData_lag.loc[pcaData_lag.Date.dt.month<m]])\n",
    "    dataset_test = pcaData_lag.loc[pcaData_lag.Date.dt.month==m]\n",
    "    print(\"Train Size: \",dataset_train.shape)\n",
    "    print(\"Test Size: \",dataset_test.shape)\n",
    "\n",
    "\n",
    "    X_train = dataset_train.drop(targetColumns+DateColumns , axis = 1)\n",
    "    X_test = dataset_test.drop(targetColumns+DateColumns , axis = 1)\n",
    "    y_train = dataset_train[targetColumns]\n",
    "    y_test = dataset_test[targetColumns]\n",
    "\n",
    "\n",
    "\n",
    "    val_last_year = len(dataset_train.loc[dataset_train.Date.dt.month==m])\n",
    "    val_last_month = len(dataset_train.loc[dataset_train.Date.dt.month==m-1])\n",
    "    if m == 1:\n",
    "        val_last_month = len(pca_data2018_lag.loc[pca_data2018_lag.Date.dt.month==12])\n",
    "#     val_fold = list(np.zeros(val_last_year)) +\\\n",
    "#                 list(-1*np.ones(len(dataset_train)-val_last_year-val_last_month)) +\\\n",
    "#                 list(np.zeros(val_last_month))\n",
    "    val_fold = list(-1*np.ones(len(dataset_train)-val_last_month)) +\\\n",
    "                list(np.zeros(val_last_month))\n",
    "    ps = PredefinedSplit(val_fold)\n",
    "    param_grid = [{\n",
    "        \"n_estimators\": np.arange(10, 200, 50),\n",
    "        \"min_samples_split\": np.arange(2, 50, 20),\n",
    "        'min_samples_leaf': np.arange(2, 50, 20), \n",
    "        'max_features': ['sqrt'],\n",
    "        'max_depth': np.arange(10, 50, 10),\n",
    "    }]\n",
    "    # fit_inverse_transform=True to make sure inverse transform available\n",
    "    rf = RandomForestRegressor(random_state = 2019) \n",
    "    rf_grid_search = GridSearchCV(rf, param_grid, cv=ps, scoring='r2')\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Train R2: \",rf_grid_search.best_estimator_.score(X_train,y_train))\n",
    "    test_r2 = rf_grid_search.best_estimator_.score(X_test,y_test)\n",
    "    print(\"Test R2: \",test_r2)\n",
    "\n",
    "\n",
    "    pca_prediction = rf_grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    residual = y_test - pca_prediction\n",
    "    residual_df = dataset_test[['Date','Hour']]\n",
    "    residual_df = pd.concat([residual_df,pd.DataFrame(residual)], axis =1)\n",
    "\n",
    "    network_prediction = inverse_pca(pca_prediction,pca)\n",
    "\n",
    "    network_prediction = inverse_standardize(network_prediction, scaler)\n",
    "    \n",
    "    # relu to convert all prediction to positive\n",
    "#     network_prediction = np.log(1+np.e**network_prediction)\n",
    "    # round up negative values to 0\n",
    "#     network_prediction = np.where(network_prediction<0,0,network_prediction)\n",
    "\n",
    "    network_prediction_df = pd.DataFrame(network_prediction)\n",
    "    network_prediction_df.columns = data.columns\n",
    "    networkPrediction = pd.concat([networkPrediction,network_prediction_df])\n",
    "\n",
    "    edge_r2 = r2_score(network_real_value.loc[network_real_value.Date.dt.month==m].drop(columns=['Date','Hour']).values, \n",
    "                       network_prediction, multioutput='variance_weighted')\n",
    "    print(\"Edge R2: \",edge_r2)\n",
    "\n",
    "\n",
    "    CommR2List.append(test_r2)\n",
    "    EdgeR2List.append(edge_r2)\n",
    "    residualDf_list.append(residual_df)\n",
    "#     rawList.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkPrediction['Date'] = data.reset_index().iloc[12:]['Date'].values\n",
    "networkPrediction['Hour'] = data.reset_index().iloc[12:]['Hour'].values\n",
    "networkPrediction.to_csv('/home/mingyi/Dropbox/UrbanTemporalNetworks/prediction/learnFrom2017/to%sPCA%s2019.csv'%(hub,pca_comps),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(CommR2List))\n",
    "print(np.mean(EdgeR2List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkPrediction[zones][networkPrediction[zones]<0] = 0\n",
    "networkPrediction.to_csv('/home/mingyi/Dropbox/UrbanTemporalNetworks/prediction/learnFrom2017/to%sPCA%s2019Round.csv'%(hub,pca_comps),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.concat(residualDf_list, axis = 0)\n",
    "res_df.to_csv('../../Resid/'+hub+'PCARoundup'+str(pca_comps)+'RFCV.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
