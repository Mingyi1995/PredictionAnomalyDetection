{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(file):\n",
    "    data = pd.read_csv(file)\n",
    "    print('Raw shape: ',data.shape)\n",
    "    data['Date'] = pd.to_datetime(data.Date)\n",
    "    print('Days: ',len(set(data.Date)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(df,zones):\n",
    "    df = df.loc[df['PULocationID'].isin(zones)]\n",
    "    table = pd.pivot_table(df, values='vehicle_count', index=['Date','Hour'],\n",
    "                    columns=['PULocationID'], aggfunc=np.sum, fill_value=0)\n",
    "#     table.columns = [i[1] for i in table.columns]\n",
    "    missing_columns = [i for i in zones if i not in table.columns]\n",
    "    for col in missing_columns:\n",
    "        table[col] = 0\n",
    "    table = table[sorted(table.columns)]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscoreNormalizeSpatial(matrix):\n",
    "    m = matrix.copy()\n",
    "    for i in range(m.shape[0]):\n",
    "        m[i, :] = (m[i, :] - m[i, :].mean()) / (m[i, :].std()+1e-10)\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(matrix):\n",
    "    m = matrix.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(m)\n",
    "    t = scaler.transform(m)\n",
    "    return scaler, t\n",
    "def inverse_standardize(matrix, scaler):\n",
    "    t = matrix.copy()\n",
    "    return scaler.inverse_transform(t)\n",
    "def getPCAFeatures(matrix, n=10):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(matrix)\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "    reducedMatrixPCA.shape\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return pca,reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_standardize(matrix, scaler):\n",
    "    t = matrix.copy()\n",
    "    return scaler.inverse_transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPCAFeatures(matrix, n=10):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(matrix)\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "    reducedMatrixPCA.shape\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return pca,reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_pca(matrix,pca):\n",
    "    m = matrix.copy()\n",
    "    return pca.inverse_transform(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLag(dataset, maxlag, lagColumns):\n",
    "    dataset_list = [dataset]\n",
    "\n",
    "    for l in range(1, maxlag+1):\n",
    "        df = dataset.shift(l)\n",
    "        df = df[lagColumns]\n",
    "        df.columns = [c+'_lag_'+str(l) for c in df.columns]\n",
    "        dataset_list.append(df)\n",
    "\n",
    "    dataset = pd.concat(dataset_list, axis=1).dropna()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train PCA from 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = gpd.read_file('../../Data/NYC Taxi Zones.geojson')\n",
    "zones = zone['location_id'].unique()\n",
    "zones = [int(i) for i in zones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = 'LGA'\n",
    "pca_comps = 6\n",
    "dataDir = '/home/mingyi/Dropbox/UrbanTemporalNetworks/processedData/'\n",
    "file = dataDir + hub + 'VehicleByHour2018toHub.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape:  (2268840, 4)\n",
      "Days:  365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-01-01</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "PULocationID     1    2    3    4    5    6    7    8    9    10   ...  254  \\\n",
       "Date       Hour                                                    ...        \n",
       "2018-01-01 0       0    0    0    0    0    0    1    0    0    0  ...    0   \n",
       "           1       0    0    0    0    0    0    0    0    0    0  ...    0   \n",
       "           2       0    0    0    0    0    0    1    0    0    0  ...    0   \n",
       "           3       0    0    0    1    0    0    4    0    0    1  ...    0   \n",
       "           4       0    0    0    2    0    0   10    0    0    1  ...    0   \n",
       "\n",
       "PULocationID     255  256  257  258  259  260  261  262  263  \n",
       "Date       Hour                                               \n",
       "2018-01-01 0       0    1    0    1    0    1    0    0    0  \n",
       "           1       0    0    0    0    0    0    0    0    0  \n",
       "           2       0    0    0    1    0    0    1    2    0  \n",
       "           3       0    1    0    0    0    1    2    2    2  \n",
       "           4       4    2    1    0    0    5    2    6    3  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2018 = loadData(file)\n",
    "data2018 = getTimeSeries(data2018,zones)\n",
    "data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2018 = data2018.values.astype(np.float64)\n",
    "scaler, s_matrix2018 = standardize(matrix2018)\n",
    "pca,pca_data2018 = getPCAFeatures(s_matrix2018,n=pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39318158211618254"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(s_matrix2018,pca.inverse_transform(pca_data2018))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = dataDir + hub + 'VehicleByHour2019toHub.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape:  (2303880, 4)\n",
      "Days:  365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8760, 260)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadData(file)\n",
    "data = getTimeSeries(data,zones)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = data.values.astype(np.float64)\n",
    "scaler, s_matrix = standardize(matrix)\n",
    "pcaData = pd.DataFrame(pca.transform(s_matrix),columns=[str(i) for i in range(1,pca_comps+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4047398408087201"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(s_matrix,pca.inverse_transform(pcaData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaData.index = data.index\n",
    "pcaData = pcaData.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "externalDataDir = \"/home/mingyi/Dropbox/UrbanTemporalNetworks/HongData/\"+hub+'2019/'\n",
    "extFile = externalDataDir+\"external.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>arrival</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>DOW</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thur</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  arrival  PRCP  SNOW  SNWD  TMAX  DOW  Tue  Wed  Thur  \\\n",
       "0  2019-01-01     0      3.0  0.06   0.0   0.0  58.0    1    1    0     0   \n",
       "1  2019-01-01     1      1.0  0.06   0.0   0.0  58.0    1    1    0     0   \n",
       "\n",
       "   Fri  Sat  Sun  \n",
       "0    0    0    0  \n",
       "1    0    0    0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf = pd.read_csv(extFile)\n",
    "print(extDf.shape)\n",
    "extDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Hour', 'arrival', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'DOW', 'Tue',\n",
       "       'Wed', 'Thur', 'Fri', 'Sat', 'Sun'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Date', 'Hour', 'arrival', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'DOW', 'Tue',\n",
    "       'Wed', 'Thur', 'Fri', 'Sat', 'Sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extDf = extDf[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.753652</td>\n",
       "      <td>-0.655313</td>\n",
       "      <td>-0.895378</td>\n",
       "      <td>-0.131793</td>\n",
       "      <td>0.456009</td>\n",
       "      <td>-0.437005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.647461</td>\n",
       "      <td>-0.702676</td>\n",
       "      <td>-0.972618</td>\n",
       "      <td>-0.190703</td>\n",
       "      <td>0.341614</td>\n",
       "      <td>-0.567476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.659045</td>\n",
       "      <td>-0.945130</td>\n",
       "      <td>-0.181405</td>\n",
       "      <td>-0.613870</td>\n",
       "      <td>0.127166</td>\n",
       "      <td>0.165909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.207054</td>\n",
       "      <td>-3.224545</td>\n",
       "      <td>3.135843</td>\n",
       "      <td>-0.718220</td>\n",
       "      <td>-0.074936</td>\n",
       "      <td>0.112813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.666761</td>\n",
       "      <td>-4.167579</td>\n",
       "      <td>3.555427</td>\n",
       "      <td>0.693335</td>\n",
       "      <td>-0.582466</td>\n",
       "      <td>-0.820200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>-10.107465</td>\n",
       "      <td>-0.946831</td>\n",
       "      <td>-0.610537</td>\n",
       "      <td>-0.135908</td>\n",
       "      <td>0.362512</td>\n",
       "      <td>-0.410524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>-9.997015</td>\n",
       "      <td>-1.132494</td>\n",
       "      <td>-0.427643</td>\n",
       "      <td>0.117013</td>\n",
       "      <td>-0.045877</td>\n",
       "      <td>-0.298086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>-10.188119</td>\n",
       "      <td>-1.188115</td>\n",
       "      <td>0.027349</td>\n",
       "      <td>-0.156123</td>\n",
       "      <td>0.445351</td>\n",
       "      <td>-0.534462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>-10.638029</td>\n",
       "      <td>-0.670126</td>\n",
       "      <td>-0.597851</td>\n",
       "      <td>-0.049798</td>\n",
       "      <td>0.240483</td>\n",
       "      <td>-0.127413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>-10.737667</td>\n",
       "      <td>-0.662564</td>\n",
       "      <td>-0.573037</td>\n",
       "      <td>0.055535</td>\n",
       "      <td>0.367281</td>\n",
       "      <td>-0.325642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         3         4         5         6\n",
       "0    -10.753652 -0.655313 -0.895378 -0.131793  0.456009 -0.437005\n",
       "1    -10.647461 -0.702676 -0.972618 -0.190703  0.341614 -0.567476\n",
       "2     -9.659045 -0.945130 -0.181405 -0.613870  0.127166  0.165909\n",
       "3     -4.207054 -3.224545  3.135843 -0.718220 -0.074936  0.112813\n",
       "4      1.666761 -4.167579  3.555427  0.693335 -0.582466 -0.820200\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "8755 -10.107465 -0.946831 -0.610537 -0.135908  0.362512 -0.410524\n",
       "8756  -9.997015 -1.132494 -0.427643  0.117013 -0.045877 -0.298086\n",
       "8757 -10.188119 -1.188115  0.027349 -0.156123  0.445351 -0.534462\n",
       "8758 -10.638029 -0.670126 -0.597851 -0.049798  0.240483 -0.127413\n",
       "8759 -10.737667 -0.662564 -0.573037  0.055535  0.367281 -0.325642\n",
       "\n",
       "[8760 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_data2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 8)\n",
      "(8760, 14)\n"
     ]
    }
   ],
   "source": [
    "print(pcaData.shape)\n",
    "print(extDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaData['Date'] = pd.to_datetime(pcaData['Date'])\n",
    "extDf['Date'] = pd.to_datetime(extDf['Date'])\n",
    "pcaData['Hour'] = pcaData['Hour'].astype(int)\n",
    "extDf['Hour'] = extDf['Hour'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 20)\n"
     ]
    }
   ],
   "source": [
    "pcaData = pd.merge(pcaData,extDf, on=['Date', 'Hour'], how='left')\n",
    "print(pcaData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Hour', '1', '2', '3', '4', '5', '6', 'arrival', 'PRCP', 'SNOW',\n",
       "       'SNWD', 'TMAX', 'DOW', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat', 'Sun'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagColumns = ['arrival'] + [str(i) for i in range(1,1+pca_comps)]\n",
    "\n",
    "DateColumns = ['Date']\n",
    "\n",
    "targetColumns = [str(i) for i in range(1,1+pca_comps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8748, 104)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlag = 12\n",
    "\n",
    "pcaData_lag = addLag(pcaData, maxlag, lagColumns)\n",
    "\n",
    "pcaData_lag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2018 data with externality\n",
    "pca_data2018.index = data2018.index\n",
    "pca_data2018 = pca_data2018.reset_index()\n",
    "externalDataDir = \"/home/mingyi/Dropbox/UrbanTemporalNetworks/HongData/\"+hub+'2018/'\n",
    "extFile = externalDataDir+\"external.csv\"\n",
    "extDf = pd.read_csv(extFile)\n",
    "extDf = extDf[selected_columns]\n",
    "\n",
    "pca_data2018['Date'] = pd.to_datetime(pca_data2018['Date'])\n",
    "extDf['Date'] = pd.to_datetime(extDf['Date'])\n",
    "pca_data2018['Hour'] = pca_data2018['Hour'].astype(int)\n",
    "extDf['Hour'] = extDf['Hour'].astype(int)\n",
    "\n",
    "pca_data2018 = pd.merge(pca_data2018,extDf, on=['Date', 'Hour'], how='left')\n",
    "\n",
    "pca_data2018_lag = addLag(pca_data2018, maxlag, lagColumns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_real_value = data[12:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month:  1\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (732, 104)\n",
      "Train R2:  0.9808710942732556\n",
      "Test R2:  0.9137447305631172\n",
      "Edge R2:  0.7645731294064233\n",
      "month:  2\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (672, 104)\n",
      "Train R2:  0.9809858393344865\n",
      "Test R2:  0.9429104979471356\n",
      "Edge R2:  0.8210639185920575\n",
      "month:  3\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9810595338867693\n",
      "Test R2:  0.9466289628323818\n",
      "Edge R2:  0.8328729342076717\n",
      "month:  4\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9813843003858357\n",
      "Test R2:  0.943079372894981\n",
      "Edge R2:  0.8291022958362901\n",
      "month:  5\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9813867209744787\n",
      "Test R2:  0.9454802742768649\n",
      "Edge R2:  0.837968779532603\n",
      "month:  6\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9815538681335214\n",
      "Test R2:  0.950805484691285\n",
      "Edge R2:  0.8336804283683503\n",
      "month:  7\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9815549315998857\n",
      "Test R2:  0.9415705951021285\n",
      "Edge R2:  0.8082157515698916\n",
      "month:  8\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9816272530405563\n",
      "Test R2:  0.9378019012941787\n",
      "Edge R2:  0.8009704879377422\n",
      "month:  9\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9813591453400533\n",
      "Test R2:  0.9469935998064443\n",
      "Edge R2:  0.8244489959669346\n",
      "month:  10\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9820658886812274\n",
      "Test R2:  0.9532268357945594\n",
      "Edge R2:  0.8358761163426982\n",
      "month:  11\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9819739243338943\n",
      "Test R2:  0.9403987134401876\n",
      "Edge R2:  0.8245712709015625\n",
      "month:  12\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9822197232478915\n",
      "Test R2:  0.9192318694452385\n",
      "Edge R2:  0.7973972952677432\n"
     ]
    }
   ],
   "source": [
    "CommR2List = []\n",
    "EdgeR2List = []\n",
    "residualDf_list = []\n",
    "rawList = []\n",
    "networkPrediction = pd.DataFrame()\n",
    "\n",
    "for m in range(1,13):\n",
    "\n",
    "    print(\"month: \",m)\n",
    "\n",
    "    dataset_train = pd.concat([pca_data2018_lag.loc[pca_data2018_lag.Date.dt.month>=m],\n",
    "                               pcaData_lag.loc[pcaData_lag.Date.dt.month<m]])\n",
    "    dataset_test = pcaData_lag.loc[pcaData_lag.Date.dt.month==m]\n",
    "    print(\"Train Size: \",dataset_train.shape)\n",
    "    print(\"Test Size: \",dataset_test.shape)\n",
    "\n",
    "\n",
    "    X_train = dataset_train.drop(targetColumns+DateColumns , axis = 1)\n",
    "    X_test = dataset_test.drop(targetColumns+DateColumns , axis = 1)\n",
    "    y_train = dataset_train[targetColumns]\n",
    "    y_test = dataset_test[targetColumns]\n",
    "\n",
    "\n",
    "\n",
    "    val_last_year = len(dataset_train.loc[dataset_train.Date.dt.month==m])\n",
    "    val_last_month = len(dataset_train.loc[dataset_train.Date.dt.month==m-1])\n",
    "    if m == 1:\n",
    "        val_last_month = len(pca_data2018_lag.loc[pca_data2018_lag.Date.dt.month==12])\n",
    "#     val_fold = list(np.zeros(val_last_year)) +\\\n",
    "#                 list(-1*np.ones(len(dataset_train)-val_last_year-val_last_month)) +\\\n",
    "#                 list(np.zeros(val_last_month))\n",
    "    val_fold = list(-1*np.ones(len(dataset_train)-val_last_month)) +\\\n",
    "                list(np.zeros(val_last_month))\n",
    "    ps = PredefinedSplit(val_fold)\n",
    "    param_grid = [{\n",
    "        \"n_estimators\": np.arange(10, 200, 50),\n",
    "        \"min_samples_split\": np.arange(2, 50, 20),\n",
    "        'min_samples_leaf': np.arange(2, 50, 20), \n",
    "        'max_features': ['sqrt'],\n",
    "        'max_depth': np.arange(10, 50, 10),\n",
    "    }]\n",
    "    # fit_inverse_transform=True to make sure inverse transform available\n",
    "    rf = RandomForestRegressor(random_state = 2019) \n",
    "    rf_grid_search = GridSearchCV(rf, param_grid, cv=ps, scoring='r2')\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Train R2: \",rf_grid_search.best_estimator_.score(X_train,y_train))\n",
    "    test_r2 = rf_grid_search.best_estimator_.score(X_test,y_test)\n",
    "    print(\"Test R2: \",test_r2)\n",
    "\n",
    "\n",
    "    pca_prediction = rf_grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    residual = y_test - pca_prediction\n",
    "    residual_df = dataset_test[['Date','Hour']]\n",
    "    residual_df = pd.concat([residual_df,pd.DataFrame(residual)], axis =1)\n",
    "\n",
    "    network_prediction = inverse_pca(pca_prediction,pca)\n",
    "\n",
    "    network_prediction = inverse_standardize(network_prediction, scaler)\n",
    "    \n",
    "    # relu to convert all prediction to positive\n",
    "#     network_prediction = np.log(1+np.e**network_prediction)\n",
    "    # round up negative values to 0\n",
    "#     network_prediction = np.where(network_prediction<0,0,network_prediction)\n",
    "\n",
    "    network_prediction_df = pd.DataFrame(network_prediction)\n",
    "    network_prediction_df.columns = data.columns\n",
    "    networkPrediction = pd.concat([networkPrediction,network_prediction_df])\n",
    "\n",
    "    edge_r2 = r2_score(network_real_value.loc[network_real_value.Date.dt.month==m].drop(columns=['Date','Hour']).values, \n",
    "                       network_prediction, multioutput='variance_weighted')\n",
    "    print(\"Edge R2: \",edge_r2)\n",
    "\n",
    "\n",
    "    CommR2List.append(test_r2)\n",
    "    EdgeR2List.append(edge_r2)\n",
    "    residualDf_list.append(residual_df)\n",
    "#     rawList.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkPrediction['Date'] = data.reset_index().iloc[12:]['Date'].values\n",
    "networkPrediction['Hour'] = data.reset_index().iloc[12:]['Hour'].values\n",
    "networkPrediction.to_csv('/home/mingyi/Dropbox/UrbanTemporalNetworks/prediction/learnFrom2017/to%sPCA%s2019.csv'%(hub,pca_comps),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9401560698407087\n",
      "0.8175617836608308\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(CommR2List))\n",
    "print(np.mean(EdgeR2List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkPrediction[zones][networkPrediction[zones]<0] = 0\n",
    "networkPrediction.to_csv('/home/mingyi/Dropbox/UrbanTemporalNetworks/prediction/learnFrom2017/to%sPCA%s2019Round.csv'%(hub,pca_comps),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.concat(residualDf_list, axis = 0)\n",
    "res_df.to_csv('../../Resid/'+hub+'PCARoundup'+str(pca_comps)+'RFCV.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
