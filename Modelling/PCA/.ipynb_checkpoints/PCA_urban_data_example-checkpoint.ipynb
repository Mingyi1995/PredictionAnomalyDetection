{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "JFKridership = pd.read_csv('../../processedData/JFKVehicleByHour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>vehicle_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOLocationID        Date  Hour  vehicle_count\n",
       "0             1  2018-01-01     0            1.0\n",
       "1             2  2018-01-01     0            0.0\n",
       "2             3  2018-01-01     0            0.0\n",
       "3             4  2018-01-01     0            1.0\n",
       "4             5  2018-01-01     0            0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JFKridership.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table\n",
    "JFKridership = pd.pivot_table(JFKridership, values='vehicle_count', index=['Date','Hour'],\n",
    "                columns=['DOLocationID'], aggfunc=np.sum, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-01-01</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "DOLocationID     1    2    3    4    5    6    7    8    9    10   ...  254  \\\n",
       "Date       Hour                                                    ...        \n",
       "2018-01-01 0       1    0    0    1    0    0    5    0    0    7  ...    0   \n",
       "           1       0    0    1    1    0    0    1    0    1    4  ...    0   \n",
       "           2       0    0    0    1    0    0    1    0    0    1  ...    0   \n",
       "           3       0    0    0    0    0    0    0    0    0    0  ...    0   \n",
       "           4       0    0    0    0    0    0    0    0    0    3  ...    0   \n",
       "\n",
       "DOLocationID     255  256  257  258  259  260  261  262  263  \n",
       "Date       Hour                                               \n",
       "2018-01-01 0       2    4    0    0    2    3    0    5    6  \n",
       "           1       2    2    1    1    0    2    0    0    1  \n",
       "           2       0    1    0    1    0    1    0    2    0  \n",
       "           3       1    0    0    2    0    0    0    0    1  \n",
       "           4       0    1    0    1    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JFKridership.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "def standardize(matrix):\n",
    "    m = matrix.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(m)\n",
    "    t = scaler.transform(m)\n",
    "    return scaler, t\n",
    "def inverse_standardize(matrix, scaler):\n",
    "    t = matrix.copy()\n",
    "    return scaler.inverse_transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction\n",
    "def getLinearPCAFeatures(matrix, n):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(matrix)\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "    reducedMatrixPCA.shape\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return pca,reducedDf\n",
    "def inversePCA(matrix,pca):\n",
    "    m = matrix.copy()\n",
    "    return pca.inverse_transform(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardscaler, matrix = standardize(JFKridership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_comps = 5\n",
    "linearPCA,linearPCAData = getLinearPCAFeatures(matrix,n=pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize the MSE between reversed PCA matrix and raw matrix\n",
    "def reverse_MSE(estimator, X):\n",
    "    X_reduced = estimator.transform(X)\n",
    "    X_reverse = estimator.inverse_transform(X_reduced)\n",
    "    return -1 * mean_squared_error(X, X_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3,\n",
       "                                 eigen_solver='auto',\n",
       "                                 fit_inverse_transform=True, gamma=None,\n",
       "                                 kernel='linear', kernel_params=None,\n",
       "                                 max_iter=None, n_components=5, n_jobs=-1,\n",
       "                                 random_state=None, remove_zero_eig=False,\n",
       "                                 tol=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'gamma': array([1.00000000e-02, 2.23111111e+00, 4.45222222e+00, 6.67333333e+00,\n",
       "       8.89444444e+00, 1.11155556e+01, 1.33366667e+01, 1.55577778e+01,\n",
       "       1.77788889e+01, 2.00000000e+01]),\n",
       "                          'kernel': ['rbf', 'sigmoid', 'poly']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=<function reverse_MSE at 0x7fbfdc315a70>, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search to find the best gamma and kernel\n",
    "param_grid = [{\n",
    "    \"gamma\": np.linspace(0.01, 20, 10),\n",
    "        \"kernel\": [\"rbf\", \"sigmoid\", \"poly\"]\n",
    "}]\n",
    "# fit_inverse_transform=True to make sure inverse transform available\n",
    "kpca=KernelPCA(fit_inverse_transform=True,n_jobs=-1, n_components=pca_comps) \n",
    "grid_search = GridSearchCV(kpca, param_grid, cv=3, scoring=reverse_MSE)\n",
    "grid_search.fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "          fit_inverse_transform=True, gamma=0.01, kernel='sigmoid',\n",
       "          kernel_params=None, max_iter=None, n_components=5, n_jobs=-1,\n",
       "          random_state=None, remove_zero_eig=False, tol=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNonLinearPCAFeatures(transformer, matrix):\n",
    "    reducedMatrixPCA = transformer.transform(matrix)\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    return transformer,reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonLinearPCA, nonLinearPCAData = getNonLinearPCAFeatures(grid_search.best_estimator_, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 12 lag value for each taxi zone\n",
    "def addLag(dataset, maxlag, lagColumns):\n",
    "    dataset_list = [dataset]\n",
    "\n",
    "    for l in range(1, maxlag+1):\n",
    "        df = dataset.shift(l)\n",
    "        df = df[lagColumns]\n",
    "        df.columns = [c+'_lag_'+str(l) for c in df.columns]\n",
    "        dataset_list.append(df)\n",
    "\n",
    "    dataset = pd.concat(dataset_list, axis=1).dropna()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagColumns = [str(i) for i in range(1,pca_comps+1)]\n",
    "DateColumns = ['Date','Hour']\n",
    "targetColumns = [str(i) for i in range(1,pca_comps+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearPCAData_lag = addLag(linearPCAData, 12, lagColumns)\n",
    "nonlinearPCAData_lag = addLag(nonLinearPCAData, 12, lagColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear PCA model training\n",
    "X, y = linearPCAData_lag.drop(columns=lagColumns+DateColumns), linearPCAData_lag[lagColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the first 11 months, test on the last month\n",
    "X_train,X_test = X.iloc[:8004], X.iloc[8004:]\n",
    "y_train,y_test = y.iloc[:8004], y.iloc[8004:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2:  0.9875490589417484\n",
      "Test R2:  0.7950724466386395\n",
      "Taxi zone leve test R2:  0.5505232677097203\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state = 2019, n_estimators=150, \n",
    "                           min_samples_split=3,\n",
    "                           min_samples_leaf= 2, \n",
    "                           max_features= 'sqrt',\n",
    "                           max_depth= None, \n",
    "                           bootstrap= False)\n",
    "rf.fit(X_train,y_train)\n",
    "print(\"Train R2: \",rf.score(X_train,y_train))\n",
    "test_r2 = rf.score(X_test,y_test)\n",
    "print(\"Test R2: \",test_r2)\n",
    "pca_prediction = rf.predict(X_test)\n",
    "taxizone_prediction = inversePCA(pca_prediction,linearPCA)\n",
    "\n",
    "taxizone_prediction = inverse_standardize(taxizone_prediction, standardscaler)\n",
    "print(\"Taxi zone leve test R2: \", r2_score(JFKridership.iloc[-744:], taxizone_prediction, multioutput='variance_weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non linear PCA model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = nonlinearPCAData_lag.drop(columns=lagColumns+DateColumns), nonlinearPCAData_lag[lagColumns]\n",
    "X_train,X_test = X.iloc[:8004], X.iloc[8004:]\n",
    "y_train,y_test = y.iloc[:8004], y.iloc[8004:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2:  0.9895053705297316\n",
      "Test R2:  0.7983319267852139\n",
      "Taxi zone leve test R2:  0.474134435314079\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state = 2019, n_estimators=150, \n",
    "                           min_samples_split=3,\n",
    "                           min_samples_leaf= 2, \n",
    "                           max_features= 'sqrt',\n",
    "                           max_depth= None, \n",
    "                           bootstrap= False)\n",
    "rf.fit(X_train,y_train)\n",
    "print(\"Train R2: \",rf.score(X_train,y_train))\n",
    "test_r2 = rf.score(X_test,y_test)\n",
    "print(\"Test R2: \",test_r2)\n",
    "pca_prediction = rf.predict(X_test)\n",
    "taxizone_prediction = inversePCA(pca_prediction,grid_search.best_estimator_)\n",
    "\n",
    "taxizone_prediction = inverse_standardize(taxizone_prediction, standardscaler)\n",
    "print(\"Taxi zone leve test R2: \", r2_score(JFKridership.iloc[-744:], taxizone_prediction, multioutput='variance_weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
