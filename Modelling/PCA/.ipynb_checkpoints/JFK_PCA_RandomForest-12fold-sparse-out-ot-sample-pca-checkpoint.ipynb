{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(file):\n",
    "    data = pd.read_csv(file)\n",
    "    print('Raw shape: ',data.shape)\n",
    "    data['Date'] = pd.to_datetime(data.Date)\n",
    "    print('Days: ',len(set(data.Date)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(df):\n",
    "    table = pd.pivot_table(df, values='vehicle_count', index=['Date','Hour','Min'],\n",
    "                    columns=['DOLocationID'], aggfunc=np.sum, fill_value=0)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscoreNormalizeSpatial(matrix):\n",
    "    m = matrix.copy()\n",
    "    for i in range(m.shape[0]):\n",
    "        m[i, :] = (m[i, :] - m[i, :].mean()) / (m[i, :].std()+1e-10)\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(matrix):\n",
    "    m = matrix.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(m)\n",
    "    t = scaler.transform(m)\n",
    "    return scaler, t\n",
    "def inverse_standardize(matrix, scaler):\n",
    "    t = matrix.copy()\n",
    "    return scaler.inverse_transform(t)\n",
    "def getPCAFeatures(matrix, n=10):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(matrix)\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "    reducedMatrixPCA.shape\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return pca,reducedDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_pca(matrix,pca):\n",
    "    m = matrix.copy()\n",
    "    return pca.inverse_transform(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLag(dataset, maxlag, lagColumns):\n",
    "    dataset_list = [dataset]\n",
    "\n",
    "    for l in range(1, maxlag+1):\n",
    "        df = dataset.shift(l)\n",
    "        df = df[lagColumns]\n",
    "        df.columns = [c+'_lag_'+str(l) for c in df.columns]\n",
    "        dataset_list.append(df)\n",
    "\n",
    "    dataset = pd.concat(dataset_list, axis=1).dropna()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(matrix1, matrix2):\n",
    "    sumSquareError = np.mean(np.power(matrix1 - matrix2,2))\n",
    "    rmse = np.power(sumSquareError,0.5)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = 'JFK'\n",
    "tune_hyp_params = False\n",
    "pca_comps = 6\n",
    "granularity = 30\n",
    "granularity = str(granularity)+'Min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '/home/mingyi/Dropbox/UrbanTemporalNetworks/processedData/'\n",
    "file = dataDir + hub + 'VehicleBy'+granularity+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = '/home/urwa/Documents/Projects/NYU Remote/project/data/JfkVehiceByHour.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape:  (1931102, 5)\n",
      "Days:  365\n"
     ]
    }
   ],
   "source": [
    "data = loadData(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getTimeSeries(data)\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17518, 262)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>DOLocationID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Min</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17513</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17514</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17515</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17516</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17517</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17518 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "DOLocationID       Date  Hour  Min  1  2  3  4  5  6  7  ...  254  255  256  \\\n",
       "0            2018-01-01     0    0  0  0  0  1  0  0  3  ...    0    2    3   \n",
       "1            2018-01-01     0   30  1  0  0  0  0  0  2  ...    0    0    1   \n",
       "2            2018-01-01     1    0  0  0  1  1  0  0  1  ...    0    1    1   \n",
       "3            2018-01-01     1   30  0  0  0  0  0  0  0  ...    0    1    1   \n",
       "4            2018-01-01     2    0  0  0  0  1  0  0  1  ...    0    0    0   \n",
       "...                 ...   ...  ... .. .. .. .. .. .. ..  ...  ...  ...  ...   \n",
       "17513        2018-12-31    21   30  0  0  0  1  0  0  9  ...    0    7    2   \n",
       "17514        2018-12-31    22    0  0  0  2  5  0  0  0  ...    2    3    3   \n",
       "17515        2018-12-31    22   30  0  0  1  0  0  0  2  ...    0    4    5   \n",
       "17516        2018-12-31    23    0  0  0  2  1  0  0  0  ...    0    6    0   \n",
       "17517        2018-12-31    23   30  1  0  0  1  0  0  6  ...    0    2    1   \n",
       "\n",
       "DOLocationID  257  258  259  260  261  262  263  \n",
       "0               0    0    1    2    0    4    6  \n",
       "1               0    0    1    1    0    1    0  \n",
       "2               0    1    0    1    0    0    1  \n",
       "3               1    0    0    1    0    0    0  \n",
       "4               0    0    0    1    0    2    0  \n",
       "...           ...  ...  ...  ...  ...  ...  ...  \n",
       "17513           5    2    0    1    1    5    9  \n",
       "17514           2    1    1    0    0    9    4  \n",
       "17515           2    1    1    0    3    4    5  \n",
       "17516           3    3    0    1    0    2    4  \n",
       "17517           3    0    0    2    1    4    5  \n",
       "\n",
       "[17518 rows x 262 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pcaData.to_csv('../../processedData/%spca%s.csv'%(hub.upper(),pca_comps),\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "externalDataDir = \"/home/mingyi/Dropbox/UrbanTemporalNetworks/HongData/\"+granularity+'/'\n",
    "extFile = externalDataDir + hub.upper() + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17520, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Min</th>\n",
       "      <th>arrival</th>\n",
       "      <th>fhv</th>\n",
       "      <th>yellow</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>ifmon</th>\n",
       "      <th>iftue</th>\n",
       "      <th>ifwed</th>\n",
       "      <th>...</th>\n",
       "      <th>maxtemp</th>\n",
       "      <th>mintemp</th>\n",
       "      <th>avgtemp</th>\n",
       "      <th>departure</th>\n",
       "      <th>hdd</th>\n",
       "      <th>cdd</th>\n",
       "      <th>participation</th>\n",
       "      <th>newsnow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>ifSnow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>263</td>\n",
       "      <td>174</td>\n",
       "      <td>437</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>263</td>\n",
       "      <td>174</td>\n",
       "      <td>437</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  Min  arrival  fhv  yellow  vehicle  ifmon  iftue  ifwed  \\\n",
       "0  2018-01-01     0    0      3.0  263     174      437      1      0      0   \n",
       "1  2018-01-01     0   30      3.0  263     174      437      1      0      0   \n",
       "\n",
       "   ...  maxtemp  mintemp  avgtemp  departure  hdd  cdd  participation  \\\n",
       "0  ...       18        7     12.5      -21.2   52    0            0.0   \n",
       "1  ...       18        7     12.5      -21.2   52    0            0.0   \n",
       "\n",
       "   newsnow  snowdepth  ifSnow  \n",
       "0      0.0          0       0  \n",
       "1      0.0          0       0  \n",
       "\n",
       "[2 rows x 48 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf = pd.read_csv(extFile)\n",
    "print(extDf.shape)\n",
    "extDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Min</th>\n",
       "      <th>arrival</th>\n",
       "      <th>fhv</th>\n",
       "      <th>yellow</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>ifmon</th>\n",
       "      <th>iftue</th>\n",
       "      <th>ifwed</th>\n",
       "      <th>...</th>\n",
       "      <th>maxtemp</th>\n",
       "      <th>mintemp</th>\n",
       "      <th>avgtemp</th>\n",
       "      <th>departure</th>\n",
       "      <th>hdd</th>\n",
       "      <th>cdd</th>\n",
       "      <th>participation</th>\n",
       "      <th>newsnow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>ifSnow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>263</td>\n",
       "      <td>174</td>\n",
       "      <td>437</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>263</td>\n",
       "      <td>174</td>\n",
       "      <td>437</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Hour  Min  arrival  fhv  yellow  vehicle  ifmon  iftue  ifwed  \\\n",
       "0 2018-01-01     0    0      3.0  263     174      437      1      0      0   \n",
       "1 2018-01-01     0   30      3.0  263     174      437      1      0      0   \n",
       "\n",
       "   ...  maxtemp  mintemp  avgtemp  departure  hdd  cdd  participation  \\\n",
       "0  ...       18        7     12.5      -21.2   52    0            0.0   \n",
       "1  ...       18        7     12.5      -21.2   52    0            0.0   \n",
       "\n",
       "   newsnow  snowdepth  ifSnow  \n",
       "0      0.0          0       0  \n",
       "1      0.0          0       0  \n",
       "\n",
       "[2 rows x 48 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf['Date'] = pd.to_datetime(extDf['Date'], yearfirst=True)\n",
    "extDf['Date'] = extDf['Date'].dt.date\n",
    "extDf['Date'] = pd.to_datetime(extDf['Date'])\n",
    "extDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Date', 'Hour', 'Min', 'arrival','maxtemp', 'mintemp', 'avgtemp', 'departure', 'hdd',\n",
    "       'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "extDf = extDf[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagColumns = [str(i) for i in range(1,pca_comps+1)]+['arrival']\n",
    "\n",
    "DateColumns = ['Date','Hour','Min']\n",
    "\n",
    "targetColumns = [str(i) for i in range(1,pca_comps+1)]\n",
    "\n",
    "maxlag = int(12 * 60 / int(granularity.replace('Min','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size:  (16030, 262)\n",
      "Test Size:  (1488, 262)\n",
      "Train R2:  0.9344777370114292\n",
      "Test R2:  0.7189529845387146\n",
      "Edge R2:  0.16044491206191738\n",
      "Train Size:  (16174, 262)\n",
      "Test Size:  (1344, 262)\n",
      "Train R2:  0.9338472388564307\n",
      "Test R2:  0.7302057179120036\n",
      "Edge R2:  0.1583149831361268\n",
      "Train Size:  (16032, 262)\n",
      "Test Size:  (1486, 262)\n",
      "Train R2:  0.9338292599244391\n",
      "Test R2:  0.7851810930977016\n",
      "Edge R2:  0.17476633401491998\n",
      "Train Size:  (16078, 262)\n",
      "Test Size:  (1440, 262)\n",
      "Train R2:  0.9346457801754023\n",
      "Test R2:  0.7577618811209649\n",
      "Edge R2:  0.17336723673842092\n",
      "Train Size:  (16030, 262)\n",
      "Test Size:  (1488, 262)\n",
      "Train R2:  0.9371115480947197\n",
      "Test R2:  0.7852148477790241\n",
      "Edge R2:  0.18455530935902686\n",
      "Train Size:  (16078, 262)\n",
      "Test Size:  (1440, 262)\n",
      "Train R2:  0.937086903391866\n",
      "Test R2:  0.7868260769649087\n",
      "Edge R2:  0.17415814020365042\n",
      "Train Size:  (16030, 262)\n",
      "Test Size:  (1488, 262)\n",
      "Train R2:  0.9374055296199101\n",
      "Test R2:  0.7582997517493687\n",
      "Edge R2:  0.1675862560311437\n",
      "Train Size:  (16030, 262)\n",
      "Test Size:  (1488, 262)\n",
      "Train R2:  0.9339497336891881\n",
      "Test R2:  0.7194959354699197\n",
      "Edge R2:  0.159515460768596\n",
      "Train Size:  (16078, 262)\n",
      "Test Size:  (1440, 262)\n",
      "Train R2:  0.9332160913295767\n",
      "Test R2:  0.8012208566085426\n",
      "Edge R2:  0.19367870883911034\n",
      "Train Size:  (16030, 262)\n",
      "Test Size:  (1488, 262)\n",
      "Train R2:  0.9364857962077611\n",
      "Test R2:  0.8046058312815209\n",
      "Edge R2:  0.1989830147376174\n",
      "Train Size:  (16078, 262)\n",
      "Test Size:  (1440, 262)\n",
      "Train R2:  0.9372543313862511\n",
      "Test R2:  0.7503440413649305\n",
      "Edge R2:  0.18226203714783487\n",
      "Train Size:  (16030, 262)\n",
      "Test Size:  (1488, 262)\n",
      "Train R2:  0.9374631147405093\n",
      "Test R2:  0.7670325104807167\n",
      "Edge R2:  0.17026893213762256\n"
     ]
    }
   ],
   "source": [
    "CommR2List = []\n",
    "EdgeR2List = []\n",
    "residualDf_list = []\n",
    "rawList = []\n",
    "networkPrediction = pd.DataFrame()\n",
    "\n",
    "for m in range(1,13):\n",
    "\n",
    "    \n",
    "    month_index  = pd.to_datetime(data.Date).dt.month == m\n",
    "\n",
    "    dataset_train = data[~month_index]\n",
    "    dataset_test = data[month_index]\n",
    "    print(\"Train Size: \",dataset_train.shape)\n",
    "    print(\"Test Size: \",dataset_test.shape)\n",
    "\n",
    "    matrix_train = dataset_train.drop(columns=DateColumns).values.astype(np.float64)\n",
    "    matrix_test = dataset_test.drop(columns=DateColumns).values.astype(np.float64)\n",
    "    scaler, s_matrix_train = standardize(matrix_train)\n",
    "    s_matrix_test = scaler.transform(matrix_test)\n",
    "    \n",
    "    pca_train_model,pca_data_train = getPCAFeatures(s_matrix_train,n=pca_comps)\n",
    "    pca_data_test = pca_train_model.transform(s_matrix_test)\n",
    "    pca_data_test = pd.DataFrame(pca_data_test)\n",
    "    pca_data_test.columns = [str(i+1) for i in pca_data_test]\n",
    "    \n",
    "    for col in DateColumns:\n",
    "        pca_data_train[col] = dataset_train[col].values\n",
    "        pca_data_test[col] = dataset_test[col].values\n",
    "    \n",
    "    pca_data_train = pca_data_train.merge(extDf, on=['Date', 'Hour','Min'], how='left').sort_values(by=['Date','Hour','Min'])\n",
    "    pca_data_train_lag = addLag(pca_data_train, maxlag, lagColumns)\n",
    "    \n",
    "    pca_data_test = pca_data_test.merge(extDf, on=['Date', 'Hour','Min'], how='left').sort_values(by=['Date','Hour','Min'])\n",
    "    pca_data_test_lag = addLag(pca_data_test, maxlag, lagColumns)\n",
    "    \n",
    "    X_train = pca_data_train_lag.drop(targetColumns+DateColumns , axis = 1)\n",
    "    X_test = pca_data_test_lag.drop(targetColumns+DateColumns , axis = 1)\n",
    "    y_train = pca_data_train_lag[targetColumns]\n",
    "    y_test = pca_data_test_lag[targetColumns]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    val_size = int(matrix_train.shape[0]*0.8)\n",
    "    val_fold = list(-1*np.ones(X_train.shape[0]-val_size)) + list(np.zeros(val_size))\n",
    "    ps = PredefinedSplit(val_fold)\n",
    "    param_grid = [{\n",
    "        \"n_estimators\": np.arange(10, 500, 50),\n",
    "        \"min_samples_split\": np.arange(2, 50, 20),\n",
    "        'min_samples_leaf': np.arange(2, 50, 20), \n",
    "        'max_features': ['sqrt'],\n",
    "        'max_depth': np.arange(10, 50, 10),\n",
    "    }]\n",
    "    # fit_inverse_transform=True to make sure inverse transform available\n",
    "    rf = RandomForestRegressor(random_state = 2019) \n",
    "    rf_grid_search = GridSearchCV(rf, param_grid, cv=ps, scoring='r2')\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Train R2: \",rf_grid_search.best_estimator_.score(X_train.values,y_train))\n",
    "    test_r2 = rf_grid_search.best_estimator_.score(X_test.values,y_test)\n",
    "    print(\"Test R2: \",test_r2)\n",
    "\n",
    "\n",
    "    pca_prediction = rf_grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    residual = y_test - pca_prediction\n",
    "    residual_df = dataset_test[['Date','Hour','Min']]\n",
    "    residual_df = pd.concat([residual_df,pd.DataFrame(residual)], axis =1)\n",
    "\n",
    "    network_prediction = inverse_pca(pca_prediction,pca_train_model)\n",
    "\n",
    "    network_prediction = inverse_standardize(network_prediction, scaler)\n",
    "    \n",
    "    # relu to convert all prediction to positive\n",
    "#     network_prediction = np.log(1+np.e**network_prediction)\n",
    "    # round up negative values to 0\n",
    "#     network_prediction = np.where(network_prediction<0,0,network_prediction)\n",
    "    network_prediction_df = pd.DataFrame(network_prediction)\n",
    "    network_prediction_df.columns = data.drop(columns=DateColumns).columns\n",
    "    networkPrediction = pd.concat([networkPrediction,network_prediction_df])\n",
    "    edgeMonthIndex = [False] * maxlag + list(month_index)\n",
    "    edge_r2 = r2_score(dataset_test[maxlag:].drop(columns=DateColumns).values, network_prediction )\n",
    "    print(\"Edge R2: \",edge_r2)\n",
    "\n",
    "\n",
    "    CommR2List.append(test_r2)\n",
    "    EdgeR2List.append(edge_r2)\n",
    "    residualDf_list.append(residual_df)\n",
    "#     rawList.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['day'] = data['Date'].astype(str).apply(lambda x: x.split('-')[-1])\n",
    "indexNames = data.loc[(data['day']=='01')&(data['Hour']<12)].index\n",
    "dataPredictMatch = data.drop(indexNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkPrediction['Date'] = dataPredictMatch.reset_index()['Date'].values\n",
    "networkPrediction['Hour'] = dataPredictMatch.reset_index()['Hour'].values\n",
    "networkPrediction.to_csv('/home/mingyi/Dropbox/UrbanTemporalNetworks/prediction/%sPCA%sComp%s.csv'%(hub,pca_comps,granularity),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763761794030693\n",
      "0.17482511043133228\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(CommR2List))\n",
    "print(np.mean(EdgeR2List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.concat(residualDf_list, axis = 0)\n",
    "res_df.to_csv('../../Resid/%sPCA%sComp%s.csv'%(hub,pca_comps,granularity),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
