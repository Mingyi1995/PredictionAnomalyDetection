{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(file):\n",
    "    data = pd.read_csv(file)\n",
    "    print('Raw shape: ',data.shape)\n",
    "    data['Date'] = pd.to_datetime(data.Date)\n",
    "    print('Days: ',len(set(data.Date)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(df,zones):\n",
    "    df = df.loc[df['DOLocationID'].isin(zones)]\n",
    "    table = pd.pivot_table(df, values='vehicle_count', index=['Date','Hour'],\n",
    "                    columns=['DOLocationID'], aggfunc=np.sum, fill_value=0)\n",
    "#     table.columns = [i[1] for i in table.columns]\n",
    "    missing_columns = [i for i in zones if i not in table.columns]\n",
    "    for col in missing_columns:\n",
    "        table[col] = 0\n",
    "    table = table[sorted(table.columns)]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscoreNormalizeSpatial(matrix):\n",
    "    m = matrix.copy()\n",
    "    for i in range(m.shape[0]):\n",
    "        m[i, :] = (m[i, :] - m[i, :].mean()) / (m[i, :].std()+1e-10)\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(matrix):\n",
    "    m = matrix.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(m)\n",
    "    t = scaler.transform(m)\n",
    "    return scaler, t\n",
    "def inverse_standardize(matrix, scaler):\n",
    "    t = matrix.copy()\n",
    "    return scaler.inverse_transform(t)\n",
    "def getPCAFeatures(matrix, n=10):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(matrix)\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "    reducedMatrixPCA.shape\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return pca,reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_standardize(matrix, scaler):\n",
    "    t = matrix.copy()\n",
    "    return scaler.inverse_transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPCAFeatures(matrix, n=10):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(matrix)\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "    reducedMatrixPCA.shape\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return pca,reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_pca(matrix,pca):\n",
    "    m = matrix.copy()\n",
    "    return pca.inverse_transform(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLag(dataset, maxlag, lagColumns):\n",
    "    dataset_list = [dataset]\n",
    "\n",
    "    for l in range(1, maxlag+1):\n",
    "        df = dataset.shift(l)\n",
    "        df = df[lagColumns]\n",
    "        df.columns = [c+'_lag_'+str(l) for c in df.columns]\n",
    "        dataset_list.append(df)\n",
    "\n",
    "    dataset = pd.concat(dataset_list, axis=1).dropna()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train PCA from 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = gpd.read_file('../../Data/NYC Taxi Zones.geojson')\n",
    "zones = zone['location_id'].unique()\n",
    "zones = [int(i) for i in zones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = 'LGA'\n",
    "pca_comps = 6\n",
    "dataDir = '/home/mingyi/Dropbox/UrbanTemporalNetworks/processedData/'\n",
    "file = dataDir + hub + 'VehicleByHour2018fromHub.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape:  (2260080, 4)\n",
      "Days:  365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-01-01</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "DOLocationID     1    2    3    4    5    6    7    8    9    10   ...  254  \\\n",
       "Date       Hour                                                    ...        \n",
       "2018-01-01 0       0    0    0    0    0    0    1    0    1    0  ...    0   \n",
       "           1       0    0    0    0    0    0    2    0    0    0  ...    0   \n",
       "           2       0    0    0    0    0    0    0    0    0    0  ...    0   \n",
       "           3       0    0    0    0    0    0    0    0    0    0  ...    0   \n",
       "           4       1    0    0    0    0    0    0    0    0    0  ...    0   \n",
       "\n",
       "DOLocationID     255  256  257  258  259  260  261  262  263  \n",
       "Date       Hour                                               \n",
       "2018-01-01 0       0    1    0    0    2    1    0    4    1  \n",
       "           1       0    0    0    0    0    0    0    0    1  \n",
       "           2       0    0    0    0    0    0    0    0    0  \n",
       "           3       0    0    0    0    0    0    0    0    0  \n",
       "           4       0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2018 = loadData(file)\n",
    "data2018 = getTimeSeries(data2018,zones)\n",
    "data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2018 = data2018.values.astype(np.float64)\n",
    "scaler, s_matrix2018 = standardize(matrix2018)\n",
    "pca,pca_data2018 = getPCAFeatures(s_matrix2018,n=pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3769178534168918"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(s_matrix2018,pca.inverse_transform(pca_data2018))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = dataDir + hub + 'VehicleByHour2019fromHub.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape:  (2295120, 4)\n",
      "Days:  365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8760, 260)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadData(file)\n",
    "data = getTimeSeries(data,zones)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = data.values.astype(np.float64)\n",
    "scaler, s_matrix = standardize(matrix)\n",
    "pcaData = pd.DataFrame(pca.transform(s_matrix),columns=[str(i) for i in range(1,pca_comps+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37368361725875504"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(s_matrix,pca.inverse_transform(pcaData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaData.index = data.index\n",
    "pcaData = pcaData.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "externalDataDir = \"/home/mingyi/Dropbox/UrbanTemporalNetworks/HongData/\"+hub+'2019/'\n",
    "extFile = externalDataDir+\"external.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>arrival</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>DOW</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thur</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  arrival  PRCP  SNOW  SNWD  TMAX  DOW  Tue  Wed  Thur  \\\n",
       "0  2019-01-01     0      3.0  0.06   0.0   0.0  58.0    1    1    0     0   \n",
       "1  2019-01-01     1      1.0  0.06   0.0   0.0  58.0    1    1    0     0   \n",
       "\n",
       "   Fri  Sat  Sun  \n",
       "0    0    0    0  \n",
       "1    0    0    0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf = pd.read_csv(extFile)\n",
    "print(extDf.shape)\n",
    "extDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Hour', 'arrival', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'DOW', 'Tue',\n",
       "       'Wed', 'Thur', 'Fri', 'Sat', 'Sun'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Date', 'Hour', 'arrival', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'DOW', 'Tue',\n",
    "       'Wed', 'Thur', 'Fri', 'Sat', 'Sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extDf = extDf[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.319823</td>\n",
       "      <td>-2.778232</td>\n",
       "      <td>1.318016</td>\n",
       "      <td>0.280364</td>\n",
       "      <td>1.165980</td>\n",
       "      <td>1.158893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11.345698</td>\n",
       "      <td>-1.051903</td>\n",
       "      <td>-0.578905</td>\n",
       "      <td>0.067536</td>\n",
       "      <td>-0.017127</td>\n",
       "      <td>0.027141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.858647</td>\n",
       "      <td>-0.979695</td>\n",
       "      <td>-0.915414</td>\n",
       "      <td>0.490049</td>\n",
       "      <td>-0.201911</td>\n",
       "      <td>0.173461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11.888261</td>\n",
       "      <td>-0.941046</td>\n",
       "      <td>-0.895775</td>\n",
       "      <td>0.410343</td>\n",
       "      <td>-0.106649</td>\n",
       "      <td>-0.045744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11.578511</td>\n",
       "      <td>-0.805717</td>\n",
       "      <td>-0.805273</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.031804</td>\n",
       "      <td>-0.239166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>0.108264</td>\n",
       "      <td>-5.158987</td>\n",
       "      <td>1.453426</td>\n",
       "      <td>0.935169</td>\n",
       "      <td>-0.789624</td>\n",
       "      <td>0.461308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>3.230547</td>\n",
       "      <td>-5.580532</td>\n",
       "      <td>1.613592</td>\n",
       "      <td>0.515881</td>\n",
       "      <td>-1.289462</td>\n",
       "      <td>1.298256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>-1.537359</td>\n",
       "      <td>-4.569780</td>\n",
       "      <td>1.753405</td>\n",
       "      <td>1.341109</td>\n",
       "      <td>0.440268</td>\n",
       "      <td>-0.712161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>-0.039644</td>\n",
       "      <td>-5.382454</td>\n",
       "      <td>3.614024</td>\n",
       "      <td>1.300752</td>\n",
       "      <td>0.535593</td>\n",
       "      <td>1.207292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>3.577823</td>\n",
       "      <td>-6.885084</td>\n",
       "      <td>4.992935</td>\n",
       "      <td>2.633652</td>\n",
       "      <td>3.555538</td>\n",
       "      <td>0.447562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         3         4         5         6\n",
       "0     -7.319823 -2.778232  1.318016  0.280364  1.165980  1.158893\n",
       "1    -11.345698 -1.051903 -0.578905  0.067536 -0.017127  0.027141\n",
       "2    -11.858647 -0.979695 -0.915414  0.490049 -0.201911  0.173461\n",
       "3    -11.888261 -0.941046 -0.895775  0.410343 -0.106649 -0.045744\n",
       "4    -11.578511 -0.805717 -0.805273 -0.210802 -0.031804 -0.239166\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "8755   0.108264 -5.158987  1.453426  0.935169 -0.789624  0.461308\n",
       "8756   3.230547 -5.580532  1.613592  0.515881 -1.289462  1.298256\n",
       "8757  -1.537359 -4.569780  1.753405  1.341109  0.440268 -0.712161\n",
       "8758  -0.039644 -5.382454  3.614024  1.300752  0.535593  1.207292\n",
       "8759   3.577823 -6.885084  4.992935  2.633652  3.555538  0.447562\n",
       "\n",
       "[8760 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_data2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 8)\n",
      "(8760, 14)\n"
     ]
    }
   ],
   "source": [
    "print(pcaData.shape)\n",
    "print(extDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaData['Date'] = pd.to_datetime(pcaData['Date'])\n",
    "extDf['Date'] = pd.to_datetime(extDf['Date'])\n",
    "pcaData['Hour'] = pcaData['Hour'].astype(int)\n",
    "extDf['Hour'] = extDf['Hour'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 20)\n"
     ]
    }
   ],
   "source": [
    "pcaData = pd.merge(pcaData,extDf, on=['Date', 'Hour'], how='left')\n",
    "print(pcaData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Hour', '1', '2', '3', '4', '5', '6', 'arrival', 'PRCP', 'SNOW',\n",
       "       'SNWD', 'TMAX', 'DOW', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat', 'Sun'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagColumns = ['arrival'] + [str(i) for i in range(1,1+pca_comps)]\n",
    "\n",
    "DateColumns = ['Date']\n",
    "\n",
    "targetColumns = [str(i) for i in range(1,1+pca_comps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8748, 104)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlag = 12\n",
    "\n",
    "pcaData_lag = addLag(pcaData, maxlag, lagColumns)\n",
    "\n",
    "pcaData_lag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2018 data with externality\n",
    "pca_data2018.index = data2018.index\n",
    "pca_data2018 = pca_data2018.reset_index()\n",
    "externalDataDir = \"/home/mingyi/Dropbox/UrbanTemporalNetworks/HongData/\"\n",
    "extFile = externalDataDir+\"external2018.csv\"\n",
    "extDf = pd.read_csv(extFile)\n",
    "extDf = extDf[selected_columns]\n",
    "\n",
    "pca_data2018['Date'] = pd.to_datetime(pca_data2018['Date'])\n",
    "extDf['Date'] = pd.to_datetime(extDf['Date'])\n",
    "pca_data2018['Hour'] = pca_data2018['Hour'].astype(int)\n",
    "extDf['Hour'] = extDf['Hour'].astype(int)\n",
    "\n",
    "pca_data2018 = pd.merge(pca_data2018,extDf, on=['Date', 'Hour'], how='left')\n",
    "\n",
    "pca_data2018_lag = addLag(pca_data2018, maxlag, lagColumns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_real_value = data[12:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month:  1\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (732, 104)\n",
      "Train R2:  0.962629721077425\n",
      "Test R2:  0.8158665587726825\n",
      "Edge R2:  0.7125814339378477\n",
      "month:  2\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (672, 104)\n",
      "Train R2:  0.9615054131271957\n",
      "Test R2:  0.8586687961757357\n",
      "Edge R2:  0.7426305097254638\n",
      "month:  3\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9627111896792805\n",
      "Test R2:  0.8791908607762129\n",
      "Edge R2:  0.7427611065467835\n",
      "month:  4\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9624032592281604\n",
      "Test R2:  0.8377835185784126\n",
      "Edge R2:  0.7453802921730213\n",
      "month:  5\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9613695433464928\n",
      "Test R2:  0.8443499935745833\n",
      "Edge R2:  0.7256374311871024\n",
      "month:  6\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9620906678542687\n",
      "Test R2:  0.8519481733735242\n",
      "Edge R2:  0.7216032075795812\n",
      "month:  7\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9618928516687943\n",
      "Test R2:  0.8592584912659867\n",
      "Edge R2:  0.7304146878281015\n",
      "month:  8\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9617317878384266\n",
      "Test R2:  0.8334205584718124\n",
      "Edge R2:  0.6910796016035504\n",
      "month:  9\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9622860152527271\n",
      "Test R2:  0.8925375549947654\n",
      "Edge R2:  0.7332954556947505\n",
      "month:  10\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9628502879285339\n",
      "Test R2:  0.8914937101815531\n",
      "Edge R2:  0.762783258735646\n",
      "month:  11\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9625744833407597\n",
      "Test R2:  0.8984441826278184\n",
      "Edge R2:  0.75055738979023\n",
      "month:  12\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9633305477294598\n",
      "Test R2:  0.8409156283421261\n",
      "Edge R2:  0.7086661740674162\n"
     ]
    }
   ],
   "source": [
    "CommR2List = []\n",
    "EdgeR2List = []\n",
    "residualDf_list = []\n",
    "rawList = []\n",
    "networkPrediction = pd.DataFrame()\n",
    "\n",
    "for m in range(1,13):\n",
    "\n",
    "    print(\"month: \",m)\n",
    "\n",
    "    dataset_train = pd.concat([pca_data2018_lag.loc[pca_data2018_lag.Date.dt.month>=m],\n",
    "                               pcaData_lag.loc[pcaData_lag.Date.dt.month<m]])\n",
    "    dataset_test = pcaData_lag.loc[pcaData_lag.Date.dt.month==m]\n",
    "    print(\"Train Size: \",dataset_train.shape)\n",
    "    print(\"Test Size: \",dataset_test.shape)\n",
    "\n",
    "\n",
    "    X_train = dataset_train.drop(targetColumns+DateColumns , axis = 1)\n",
    "    X_test = dataset_test.drop(targetColumns+DateColumns , axis = 1)\n",
    "    y_train = dataset_train[targetColumns]\n",
    "    y_test = dataset_test[targetColumns]\n",
    "\n",
    "\n",
    "\n",
    "    val_last_year = len(dataset_train.loc[dataset_train.Date.dt.month==m])\n",
    "    val_last_month = len(dataset_train.loc[dataset_train.Date.dt.month==m-1])\n",
    "    if m == 1:\n",
    "        val_last_month = len(pca_data2018_lag.loc[pca_data2018_lag.Date.dt.month==12])\n",
    "#     val_fold = list(np.zeros(val_last_year)) +\\\n",
    "#                 list(-1*np.ones(len(dataset_train)-val_last_year-val_last_month)) +\\\n",
    "#                 list(np.zeros(val_last_month))\n",
    "    val_fold = list(-1*np.ones(len(dataset_train)-val_last_month)) +\\\n",
    "                list(np.zeros(val_last_month))\n",
    "    ps = PredefinedSplit(val_fold)\n",
    "    param_grid = [{\n",
    "        \"n_estimators\": np.arange(10, 200, 50),\n",
    "        \"min_samples_split\": np.arange(2, 50, 20),\n",
    "        'min_samples_leaf': np.arange(2, 50, 20), \n",
    "        'max_features': ['sqrt'],\n",
    "        'max_depth': np.arange(10, 50, 10),\n",
    "    }]\n",
    "    # fit_inverse_transform=True to make sure inverse transform available\n",
    "    rf = RandomForestRegressor(random_state = 2019) \n",
    "    rf_grid_search = GridSearchCV(rf, param_grid, cv=ps, scoring='r2')\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Train R2: \",rf_grid_search.best_estimator_.score(X_train,y_train))\n",
    "    test_r2 = rf_grid_search.best_estimator_.score(X_test,y_test)\n",
    "    print(\"Test R2: \",test_r2)\n",
    "\n",
    "\n",
    "    pca_prediction = rf_grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    residual = y_test - pca_prediction\n",
    "    residual_df = dataset_test[['Date','Hour']]\n",
    "    residual_df = pd.concat([residual_df,pd.DataFrame(residual)], axis =1)\n",
    "\n",
    "    network_prediction = inverse_pca(pca_prediction,pca)\n",
    "\n",
    "    network_prediction = inverse_standardize(network_prediction, scaler)\n",
    "    \n",
    "    # relu to convert all prediction to positive\n",
    "#     network_prediction = np.log(1+np.e**network_prediction)\n",
    "    # round up negative values to 0\n",
    "#     network_prediction = np.where(network_prediction<0,0,network_prediction)\n",
    "\n",
    "    network_prediction_df = pd.DataFrame(network_prediction)\n",
    "    network_prediction_df.columns = data.columns\n",
    "    networkPrediction = pd.concat([networkPrediction,network_prediction_df])\n",
    "\n",
    "    edge_r2 = r2_score(network_real_value.loc[network_real_value.Date.dt.month==m].drop(columns=['Date','Hour']).values, \n",
    "                       network_prediction, multioutput='variance_weighted')\n",
    "    print(\"Edge R2: \",edge_r2)\n",
    "\n",
    "\n",
    "    CommR2List.append(test_r2)\n",
    "    EdgeR2List.append(edge_r2)\n",
    "    residualDf_list.append(residual_df)\n",
    "#     rawList.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkPrediction['Date'] = data.reset_index().iloc[12:]['Date'].values\n",
    "networkPrediction['Hour'] = data.reset_index().iloc[12:]['Hour'].values\n",
    "networkPrediction.to_csv('/home/mingyi/Dropbox/UrbanTemporalNetworks/prediction/learnFrom2017/from%sPCA%s2019.csv'%(hub,pca_comps),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8586565022612677\n",
      "0.7306158790724578\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(CommR2List))\n",
    "print(np.mean(EdgeR2List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkPrediction[zones][networkPrediction[zones]<0] = 0\n",
    "networkPrediction.to_csv('/home/mingyi/Dropbox/UrbanTemporalNetworks/prediction/learnFrom2017/from%sPCA%s2019Round.csv'%(hub,pca_comps),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.concat(residualDf_list, axis = 0)\n",
    "res_df.to_csv('../../Resid/'+hub+'PCARoundup'+str(pca_comps)+'RFCV.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
