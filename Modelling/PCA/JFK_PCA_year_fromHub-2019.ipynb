{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(file):\n",
    "    data = pd.read_csv(file)\n",
    "    print('Raw shape: ',data.shape)\n",
    "    data['Date'] = pd.to_datetime(data.Date)\n",
    "    print('Days: ',len(set(data.Date)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(df,zones):\n",
    "    df = df.loc[df['DOLocationID'].isin(zones)]\n",
    "    table = pd.pivot_table(df, values='vehicle_count', index=['Date','Hour'],\n",
    "                    columns=['DOLocationID'], aggfunc=np.sum, fill_value=0)\n",
    "#     table.columns = [i[1] for i in table.columns]\n",
    "    missing_columns = [i for i in zones if i not in table.columns]\n",
    "    for col in missing_columns:\n",
    "        table[col] = 0\n",
    "    table = table[sorted(table.columns)]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscoreNormalizeSpatial(matrix):\n",
    "    m = matrix.copy()\n",
    "    for i in range(m.shape[0]):\n",
    "        m[i, :] = (m[i, :] - m[i, :].mean()) / (m[i, :].std()+1e-10)\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(matrix):\n",
    "    m = matrix.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(m)\n",
    "    t = scaler.transform(m)\n",
    "    return scaler, t\n",
    "def inverse_standardize(matrix, scaler):\n",
    "    t = matrix.copy()\n",
    "    return scaler.inverse_transform(t)\n",
    "def getPCAFeatures(matrix, n=10):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(matrix)\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "    reducedMatrixPCA.shape\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return pca,reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_standardize(matrix, scaler):\n",
    "    t = matrix.copy()\n",
    "    return scaler.inverse_transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPCAFeatures(matrix, n=10):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(matrix)\n",
    "    reducedMatrixPCA = pca.transform(matrix)\n",
    "    reducedMatrixPCA.shape\n",
    "\n",
    "    reducedDict = {str(i+1):reducedMatrixPCA[:,i] for i in range(reducedMatrixPCA.shape[1])}\n",
    "    reducedDf = pd.DataFrame(reducedDict)\n",
    "    #reducedDf.index = index\n",
    "    return pca,reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_pca(matrix,pca):\n",
    "    m = matrix.copy()\n",
    "    return pca.inverse_transform(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLag(dataset, maxlag, lagColumns):\n",
    "    dataset_list = [dataset]\n",
    "\n",
    "    for l in range(1, maxlag+1):\n",
    "        df = dataset.shift(l)\n",
    "        df = df[lagColumns]\n",
    "        df.columns = [c+'_lag_'+str(l) for c in df.columns]\n",
    "        dataset_list.append(df)\n",
    "\n",
    "    dataset = pd.concat(dataset_list, axis=1).dropna()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train PCA from 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = gpd.read_file('../../Data/NYC Taxi Zones.geojson')\n",
    "zones = zone['location_id'].unique()\n",
    "zones = [int(i) for i in zones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = 'JFK'\n",
    "pca_comps = 6\n",
    "dataDir = '/home/mingyi/Dropbox/UrbanTemporalNetworks/processedData/'\n",
    "file = dataDir + hub + 'VehicleByHour2018fromHub.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape:  (2268840, 4)\n",
      "Days:  365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-01-01</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "DOLocationID     1    2    3    4    5    6    7    8    9    10   ...  254  \\\n",
       "Date       Hour                                                    ...        \n",
       "2018-01-01 0       1    0    0    1    0    0    5    0    0    7  ...    0   \n",
       "           1       0    0    1    1    0    0    1    0    1    4  ...    0   \n",
       "           2       0    0    0    1    0    0    1    0    0    1  ...    0   \n",
       "           3       0    0    0    0    0    0    0    0    0    0  ...    0   \n",
       "           4       0    0    0    0    0    0    0    0    0    3  ...    0   \n",
       "\n",
       "DOLocationID     255  256  257  258  259  260  261  262  263  \n",
       "Date       Hour                                               \n",
       "2018-01-01 0       2    4    0    0    2    3    0    5    6  \n",
       "           1       2    2    1    1    0    2    0    0    1  \n",
       "           2       0    1    0    1    0    1    0    2    0  \n",
       "           3       1    0    0    2    0    0    0    0    1  \n",
       "           4       0    1    0    1    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2018 = loadData(file)\n",
    "data2018 = getTimeSeries(data2018,zones)\n",
    "data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2018 = data2018.values.astype(np.float64)\n",
    "scaler, s_matrix2018 = standardize(matrix2018)\n",
    "pca,pca_data2018 = getPCAFeatures(s_matrix2018,n=pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3238709760099891"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(s_matrix2018,pca.inverse_transform(pca_data2018))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = 'JFK'\n",
    "file = dataDir + hub + 'VehicleByHour2019fromHub.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape:  (2295120, 4)\n",
      "Days:  365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8760, 260)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadData(file)\n",
    "data = getTimeSeries(data,zones)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = data.values.astype(np.float64)\n",
    "scaler, s_matrix = standardize(matrix)\n",
    "pcaData = pd.DataFrame(pca.transform(s_matrix),columns=[str(i) for i in range(1,pca_comps+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3232405656159446"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(s_matrix,pca.inverse_transform(pcaData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaData.index = data.index\n",
    "pcaData = pcaData.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "externalDataDir = \"/home/mingyi/Dropbox/UrbanTemporalNetworks/HongData/\"+hub+'2019/'\n",
    "extFile = externalDataDir+\"external.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>arrival</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>DOW</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thur</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  arrival  PRCP  SNOW  SNWD  TMAX  DOW  Tue  Wed  Thur  \\\n",
       "0  2019-01-01     0      7.0  0.06   0.0   0.0  58.0    1    1    0     0   \n",
       "1  2019-01-01     1      1.0  0.06   0.0   0.0  58.0    1    1    0     0   \n",
       "\n",
       "   Fri  Sat  Sun  \n",
       "0    0    0    0  \n",
       "1    0    0    0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf = pd.read_csv(extFile)\n",
    "print(extDf.shape)\n",
    "extDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Hour', 'arrival', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'DOW', 'Tue',\n",
       "       'Wed', 'Thur', 'Fri', 'Sat', 'Sun'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Date', 'Hour', 'arrival', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'DOW', 'Tue',\n",
    "       'Wed', 'Thur', 'Fri', 'Sat', 'Sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extDf = extDf[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.588562</td>\n",
       "      <td>4.393972</td>\n",
       "      <td>1.528272</td>\n",
       "      <td>0.915964</td>\n",
       "      <td>-0.485206</td>\n",
       "      <td>-0.862172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.963274</td>\n",
       "      <td>3.220824</td>\n",
       "      <td>0.531684</td>\n",
       "      <td>1.292945</td>\n",
       "      <td>-1.604876</td>\n",
       "      <td>0.405257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-12.807477</td>\n",
       "      <td>0.654048</td>\n",
       "      <td>1.848285</td>\n",
       "      <td>-0.139043</td>\n",
       "      <td>-0.503030</td>\n",
       "      <td>0.231892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.669137</td>\n",
       "      <td>0.381856</td>\n",
       "      <td>1.661397</td>\n",
       "      <td>-0.075564</td>\n",
       "      <td>-0.369869</td>\n",
       "      <td>0.188619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12.983212</td>\n",
       "      <td>0.557505</td>\n",
       "      <td>1.068529</td>\n",
       "      <td>-0.578112</td>\n",
       "      <td>0.405943</td>\n",
       "      <td>-0.155874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>11.880840</td>\n",
       "      <td>4.607175</td>\n",
       "      <td>2.461575</td>\n",
       "      <td>1.045820</td>\n",
       "      <td>0.689446</td>\n",
       "      <td>-3.027006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>8.048243</td>\n",
       "      <td>5.494914</td>\n",
       "      <td>3.000300</td>\n",
       "      <td>-0.447031</td>\n",
       "      <td>-2.832418</td>\n",
       "      <td>-2.472481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>9.078574</td>\n",
       "      <td>7.724551</td>\n",
       "      <td>3.807493</td>\n",
       "      <td>-0.502671</td>\n",
       "      <td>-1.242993</td>\n",
       "      <td>-0.844255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>7.548258</td>\n",
       "      <td>8.058080</td>\n",
       "      <td>0.622593</td>\n",
       "      <td>0.775275</td>\n",
       "      <td>0.450685</td>\n",
       "      <td>-0.787450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>5.214854</td>\n",
       "      <td>8.716921</td>\n",
       "      <td>0.113126</td>\n",
       "      <td>2.095877</td>\n",
       "      <td>-1.797739</td>\n",
       "      <td>-2.361426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         3         4         5         6\n",
       "0     -3.588562  4.393972  1.528272  0.915964 -0.485206 -0.862172\n",
       "1     -7.963274  3.220824  0.531684  1.292945 -1.604876  0.405257\n",
       "2    -12.807477  0.654048  1.848285 -0.139043 -0.503030  0.231892\n",
       "3    -13.669137  0.381856  1.661397 -0.075564 -0.369869  0.188619\n",
       "4    -12.983212  0.557505  1.068529 -0.578112  0.405943 -0.155874\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "8755  11.880840  4.607175  2.461575  1.045820  0.689446 -3.027006\n",
       "8756   8.048243  5.494914  3.000300 -0.447031 -2.832418 -2.472481\n",
       "8757   9.078574  7.724551  3.807493 -0.502671 -1.242993 -0.844255\n",
       "8758   7.548258  8.058080  0.622593  0.775275  0.450685 -0.787450\n",
       "8759   5.214854  8.716921  0.113126  2.095877 -1.797739 -2.361426\n",
       "\n",
       "[8760 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_data2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 8)\n",
      "(8760, 14)\n"
     ]
    }
   ],
   "source": [
    "print(pcaData.shape)\n",
    "print(extDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaData['Date'] = pd.to_datetime(pcaData['Date'])\n",
    "extDf['Date'] = pd.to_datetime(extDf['Date'])\n",
    "pcaData['Hour'] = pcaData['Hour'].astype(int)\n",
    "extDf['Hour'] = extDf['Hour'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 20)\n"
     ]
    }
   ],
   "source": [
    "pcaData = pd.merge(pcaData,extDf, on=['Date', 'Hour'], how='left')\n",
    "print(pcaData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Hour', '1', '2', '3', '4', '5', '6', 'arrival', 'PRCP', 'SNOW',\n",
       "       'SNWD', 'TMAX', 'DOW', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat', 'Sun'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagColumns = ['arrival'] + [str(i) for i in range(1,1+pca_comps)]\n",
    "\n",
    "DateColumns = ['Date']\n",
    "\n",
    "targetColumns = [str(i) for i in range(1,1+pca_comps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8748, 104)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlag = 12\n",
    "\n",
    "pcaData_lag = addLag(pcaData, maxlag, lagColumns)\n",
    "\n",
    "pcaData_lag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2018 data with externality\n",
    "pca_data2018.index = data2018.index\n",
    "pca_data2018 = pca_data2018.reset_index()\n",
    "externalDataDir = \"/home/mingyi/Dropbox/UrbanTemporalNetworks/HongData/\"+hub+'2018/'\n",
    "extFile = externalDataDir+\"external.csv\"\n",
    "extDf = pd.read_csv(extFile)\n",
    "extDf = extDf[selected_columns]\n",
    "\n",
    "pca_data2018['Date'] = pd.to_datetime(pca_data2018['Date'])\n",
    "extDf['Date'] = pd.to_datetime(extDf['Date'])\n",
    "pca_data2018['Hour'] = pca_data2018['Hour'].astype(int)\n",
    "extDf['Hour'] = extDf['Hour'].astype(int)\n",
    "\n",
    "pca_data2018 = pd.merge(pca_data2018,extDf, on=['Date', 'Hour'], how='left')\n",
    "\n",
    "pca_data2018_lag = addLag(pca_data2018, maxlag, lagColumns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "month:  1\n",
      "Train Size:  (8016, 104)\n",
      "Test Size:  (732, 104)\n",
      "Train R2:  0.9474907003418086\n",
      "Test R2:  0.7602312393589121\n",
      "Edge R2:  0.4970566836001448\n",
      "\n",
      "month:  2\n",
      "Train Size:  (8076, 104)\n",
      "Test Size:  (672, 104)\n",
      "Train R2:  0.9465226394642942\n",
      "Test R2:  0.7806003984223646\n",
      "Edge R2:  0.5365418100044741\n",
      "\n",
      "month:  3\n",
      "Train Size:  (8004, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9463637056454515\n",
      "Test R2:  0.8386673089576178\n",
      "Edge R2:  0.585503625407202\n",
      "\n",
      "month:  4\n",
      "Train Size:  (8028, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9489299379739523\n",
      "Test R2:  0.7789686031253396\n",
      "Edge R2:  0.556634956110667\n",
      "\n",
      "month:  5\n",
      "Train Size:  (8004, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9478686673958027\n",
      "Test R2:  0.816198516628748\n",
      "Edge R2:  0.4863003427315099\n",
      "\n",
      "month:  6\n",
      "Train Size:  (8028, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9481372813839379\n",
      "Test R2:  0.8036782043017064\n",
      "Edge R2:  0.5308021788312349\n",
      "\n",
      "month:  7\n",
      "Train Size:  (8004, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9485424325764092\n",
      "Test R2:  0.7676145293256248\n",
      "Edge R2:  0.49645650565687927\n",
      "\n",
      "month:  8\n",
      "Train Size:  (8004, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9483253732607192\n",
      "Test R2:  0.7442886912082857\n",
      "Edge R2:  0.4981818586597387\n",
      "\n",
      "month:  9\n",
      "Train Size:  (8028, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9470260862336335\n",
      "Test R2:  0.8469909531373658\n",
      "Edge R2:  0.5732363040197362\n",
      "\n",
      "month:  10\n",
      "Train Size:  (8004, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9471547397774726\n",
      "Test R2:  0.8403519066501223\n",
      "Edge R2:  0.583811746767256\n",
      "\n",
      "month:  11\n",
      "Train Size:  (8028, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9474504924424496\n",
      "Test R2:  0.8359829365671969\n",
      "Edge R2:  0.5653491313836717\n",
      "\n",
      "month:  12\n",
      "Train Size:  (8004, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9477767974554919\n",
      "Test R2:  0.7886599074743825\n",
      "Edge R2:  0.4981440779597301\n"
     ]
    }
   ],
   "source": [
    "CommR2List = []\n",
    "EdgeR2List = []\n",
    "residualDf_list = []\n",
    "rawList = []\n",
    "networkPrediction = pd.DataFrame()\n",
    "\n",
    "for m in range(1,13):\n",
    "    print()\n",
    "\n",
    "    print(\"month: \",m)\n",
    "    month_index  = pd.to_datetime(pcaData_lag.Date).dt.month == m\n",
    "\n",
    "    dataset_train = pcaData_lag[~month_index]\n",
    "    dataset_test = pcaData_lag[month_index]\n",
    "    print(\"Train Size: \",dataset_train.shape)\n",
    "    print(\"Test Size: \",dataset_test.shape)\n",
    "\n",
    "\n",
    "    X_train = dataset_train.drop(targetColumns+DateColumns , axis = 1)\n",
    "    X_test = dataset_test.drop(targetColumns+DateColumns , axis = 1)\n",
    "    y_train = dataset_train[targetColumns]\n",
    "    y_test = dataset_test[targetColumns]\n",
    "\n",
    "\n",
    "\n",
    "    val_size = int(X_train.shape[0]*0.8)\n",
    "    val_fold = list(-1*np.ones(X_train.shape[0]-val_size)) + list(np.zeros(val_size))\n",
    "    ps = PredefinedSplit(val_fold)\n",
    "    param_grid = [{\n",
    "        \"n_estimators\": np.arange(10, 500, 50),\n",
    "        \"min_samples_split\": np.arange(2, 50, 20),\n",
    "        'min_samples_leaf': np.arange(2, 50, 20), \n",
    "        'max_features': ['sqrt'],\n",
    "        'max_depth': np.arange(10, 50, 10),\n",
    "    }]\n",
    "    # fit_inverse_transform=True to make sure inverse transform available\n",
    "    rf = RandomForestRegressor(random_state = 2019) \n",
    "    rf_grid_search = GridSearchCV(rf, param_grid, cv=ps, scoring='r2')\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Train R2: \",rf_grid_search.best_estimator_.score(X_train,y_train))\n",
    "    test_r2 = rf_grid_search.best_estimator_.score(X_test,y_test)\n",
    "    print(\"Test R2: \",test_r2)\n",
    "\n",
    "\n",
    "    pca_prediction = rf_grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    residual = y_test - pca_prediction\n",
    "    residual_df = dataset_test[['Date','Hour']]\n",
    "    residual_df = pd.concat([residual_df,pd.DataFrame(residual)], axis =1)\n",
    "\n",
    "    network_prediction = inverse_pca(pca_prediction,pca)\n",
    "\n",
    "    network_prediction = inverse_standardize(network_prediction, scaler)\n",
    "    \n",
    "    # relu to convert all prediction to positive\n",
    "#     network_prediction = np.log(1+np.e**network_prediction)\n",
    "    # round up negative values to 0\n",
    "#     network_prediction = np.where(network_prediction<0,0,network_prediction)\n",
    "\n",
    "    network_prediction_df = pd.DataFrame(network_prediction)\n",
    "    network_prediction_df.columns = data.columns\n",
    "    networkPrediction = pd.concat([networkPrediction,network_prediction_df])\n",
    "    edgeMonthIndex = [False] * maxlag + list(month_index)\n",
    "    edge_r2 = r2_score(data[edgeMonthIndex], network_prediction, multioutput='variance_weighted')\n",
    "    print(\"Edge R2: \",edge_r2)\n",
    "\n",
    "\n",
    "    CommR2List.append(test_r2)\n",
    "    EdgeR2List.append(edge_r2)\n",
    "    residualDf_list.append(residual_df)\n",
    "#     rawList.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_real_value = data[12:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month:  1\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (732, 104)\n",
      "Train R2:  0.9465393022271196\n",
      "Test R2:  0.770449773773492\n",
      "Edge R2:  0.5102841139426799\n",
      "month:  2\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (672, 104)\n",
      "Train R2:  0.9466766902432138\n",
      "Test R2:  0.8041052517723392\n",
      "Edge R2:  0.554190072390432\n",
      "month:  3\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9484760461165993\n",
      "Test R2:  0.8394898626703631\n",
      "Edge R2:  0.5854219126247516\n",
      "month:  4\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9476480208232959\n",
      "Test R2:  0.7849850931937852\n",
      "Edge R2:  0.55561770701177\n",
      "month:  5\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9482688083503775\n",
      "Test R2:  0.8242543326702986\n",
      "Edge R2:  0.48821000138264914\n",
      "month:  6\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9482046455680097\n",
      "Test R2:  0.8038700505931252\n",
      "Edge R2:  0.5296313471381865\n",
      "month:  7\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.946252694313724\n",
      "Test R2:  0.7677801213114418\n",
      "Edge R2:  0.49444913173928384\n",
      "month:  8\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9473747249234055\n",
      "Test R2:  0.7711847539503636\n",
      "Edge R2:  0.5018938279652165\n",
      "month:  9\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9476157927640636\n",
      "Test R2:  0.8448055403675806\n",
      "Edge R2:  0.5723428457743012\n",
      "month:  10\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9470082238883691\n",
      "Test R2:  0.8401953043366399\n",
      "Edge R2:  0.5848795800209321\n",
      "month:  11\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (720, 104)\n",
      "Train R2:  0.9456901922871217\n",
      "Test R2:  0.8367304580304019\n",
      "Edge R2:  0.5657869280826807\n",
      "month:  12\n",
      "Train Size:  (8748, 104)\n",
      "Test Size:  (744, 104)\n",
      "Train R2:  0.9464193930250363\n",
      "Test R2:  0.8017842034635507\n",
      "Edge R2:  0.5090732832593035\n"
     ]
    }
   ],
   "source": [
    "CommR2List = []\n",
    "EdgeR2List = []\n",
    "residualDf_list = []\n",
    "rawList = []\n",
    "networkPrediction = pd.DataFrame()\n",
    "\n",
    "for m in range(1,13):\n",
    "\n",
    "    print(\"month: \",m)\n",
    "\n",
    "    dataset_train = pd.concat([pca_data2018_lag.loc[pca_data2018_lag.Date.dt.month>=m],\n",
    "                               pcaData_lag.loc[pcaData_lag.Date.dt.month<m]])\n",
    "    dataset_test = pcaData_lag.loc[pcaData_lag.Date.dt.month==m]\n",
    "    print(\"Train Size: \",dataset_train.shape)\n",
    "    print(\"Test Size: \",dataset_test.shape)\n",
    "\n",
    "\n",
    "    X_train = dataset_train.drop(targetColumns+DateColumns , axis = 1)\n",
    "    X_test = dataset_test.drop(targetColumns+DateColumns , axis = 1)\n",
    "    y_train = dataset_train[targetColumns]\n",
    "    y_test = dataset_test[targetColumns]\n",
    "\n",
    "\n",
    "\n",
    "    val_last_year = len(dataset_train.loc[dataset_train.Date.dt.month==m])\n",
    "    val_last_month = len(dataset_train.loc[dataset_train.Date.dt.month==m-1])\n",
    "    if m == 1:\n",
    "        val_last_month = len(pca_data2018_lag.loc[pca_data2018_lag.Date.dt.month==12])\n",
    "#     val_fold = list(np.zeros(val_last_year)) +\\\n",
    "#                 list(-1*np.ones(len(dataset_train)-val_last_year-val_last_month)) +\\\n",
    "#                 list(np.zeros(val_last_month))\n",
    "    val_fold = list(-1*np.ones(len(dataset_train)-val_last_month)) +\\\n",
    "                list(np.zeros(val_last_month))\n",
    "    ps = PredefinedSplit(val_fold)\n",
    "    param_grid = [{\n",
    "        \"n_estimators\": np.arange(10, 200, 50),\n",
    "        \"min_samples_split\": np.arange(2, 50, 20),\n",
    "        'min_samples_leaf': np.arange(2, 50, 20), \n",
    "        'max_features': ['sqrt'],\n",
    "        'max_depth': np.arange(10, 50, 10),\n",
    "    }]\n",
    "    # fit_inverse_transform=True to make sure inverse transform available\n",
    "    rf = RandomForestRegressor(random_state = 2019) \n",
    "    rf_grid_search = GridSearchCV(rf, param_grid, cv=ps, scoring='r2')\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Train R2: \",rf_grid_search.best_estimator_.score(X_train,y_train))\n",
    "    test_r2 = rf_grid_search.best_estimator_.score(X_test,y_test)\n",
    "    print(\"Test R2: \",test_r2)\n",
    "\n",
    "\n",
    "    pca_prediction = rf_grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    residual = y_test - pca_prediction\n",
    "    residual_df = dataset_test[['Date','Hour']]\n",
    "    residual_df = pd.concat([residual_df,pd.DataFrame(residual)], axis =1)\n",
    "\n",
    "    network_prediction = inverse_pca(pca_prediction,pca)\n",
    "\n",
    "    network_prediction = inverse_standardize(network_prediction, scaler)\n",
    "    \n",
    "    # relu to convert all prediction to positive\n",
    "#     network_prediction = np.log(1+np.e**network_prediction)\n",
    "    # round up negative values to 0\n",
    "#     network_prediction = np.where(network_prediction<0,0,network_prediction)\n",
    "\n",
    "    network_prediction_df = pd.DataFrame(network_prediction)\n",
    "    network_prediction_df.columns = data.columns\n",
    "    networkPrediction = pd.concat([networkPrediction,network_prediction_df])\n",
    "\n",
    "    edge_r2 = r2_score(network_real_value.loc[network_real_value.Date.dt.month==m].drop(columns=['Date','Hour']).values, \n",
    "                       network_prediction, multioutput='variance_weighted')\n",
    "    print(\"Edge R2: \",edge_r2)\n",
    "\n",
    "\n",
    "    CommR2List.append(test_r2)\n",
    "    EdgeR2List.append(edge_r2)\n",
    "    residualDf_list.append(residual_df)\n",
    "#     rawList.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkPrediction['Date'] = data.reset_index().iloc[12:]['Date'].values\n",
    "networkPrediction['Hour'] = data.reset_index().iloc[12:]['Hour'].values\n",
    "networkPrediction.to_csv('/home/mingyi/Dropbox/UrbanTemporalNetworks/prediction/learnFrom2017/from%sPCA%s2019.csv'%(hub,pca_comps),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8074695621777819\n",
      "0.5376483959443491\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(CommR2List))\n",
    "print(np.mean(EdgeR2List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkPrediction[zones][networkPrediction[zones]<0] = 0\n",
    "networkPrediction.to_csv('/home/mingyi/Dropbox/UrbanTemporalNetworks/prediction/learnFrom2017/from%sPCA%s2019Round.csv'%(hub,pca_comps),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.concat(residualDf_list, axis = 0)\n",
    "res_df.to_csv('../../Resid/'+hub+'PCARoundup'+str(pca_comps)+'RFCV.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
